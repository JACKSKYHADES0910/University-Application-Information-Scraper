# -*- coding: utf-8 -*-
"""
é˜¿å°”æ–¯ç‰¹å¤§å­¦ (Ulster University) çˆ¬è™«æ¨¡å—
è´Ÿè´£æŠ“å– Ulster Postgraduate é¡¹ç›®ä¿¡æ¯
"""

import time
import re
from typing import List, Dict
from urllib.parse import urljoin, urlparse, parse_qs, unquote
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from spiders.base_spider import BaseSpider
from utils.browser import get_driver
from utils.progress import CrawlerProgress, print_phase_start, print_phase_complete
from utils.selenium_utils import BrowserPool, safe_click
from config import MAX_WORKERS, PAGE_LOAD_WAIT


class UlsterSpider(BaseSpider):
    """
    é˜¿å°”æ–¯ç‰¹å¤§å­¦çˆ¬è™«
    
    è´Ÿè´£ä» Ulster University å®˜ç½‘çˆ¬å–æ‰€æœ‰ Postgraduate é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯,åŒ…æ‹¬:
    - é¡¹ç›®åç§°
    - é¡¹ç›®é“¾æ¥
    - å¼€å§‹æ—¥æœŸ
    - ç”³è¯·æˆªæ­¢æ—¥æœŸ(å¦‚æœæœ‰)
    - ç»Ÿä¸€çš„ç”³è¯·æ³¨å†Œå’Œç™»å½•é“¾æ¥
    
    ä½¿ç”¨ç¤ºä¾‹:
        >>> with UlsterSpider() as spider:
        ...     data = spider.run()
        ...     print(f"çˆ¬å–äº† {len(data)} æ¡æ•°æ®")
    """
    
    def __init__(self, headless: bool = True, max_workers: int = None):
        """
        åˆå§‹åŒ– Ulster çˆ¬è™«
        
        å‚æ•°:
            headless (bool): æ˜¯å¦æ— å¤´æ¨¡å¼è¿è¡Œ
            max_workers (int): å¹¶å‘çº¿ç¨‹æ•°,å¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨ config.py ä¸­çš„é…ç½®
        """
        super().__init__("ulster", headless)
        from config import MAX_WORKERS as CONFIG_MAX_WORKERS
        self.max_workers = max_workers if max_workers is not None else CONFIG_MAX_WORKERS
        self.temp_links: List[Dict] = []  # ä¸´æ—¶å­˜å‚¨é¡¹ç›®é“¾æ¥åˆ—è¡¨
        self.progress_manager: CrawlerProgress = None  # è¿›åº¦ç®¡ç†å™¨
        self.browser_pool: BrowserPool = None  # æµè§ˆå™¨æ± 
    
    def run(self) -> List[Dict]:
        """
        æ‰§è¡Œå®Œæ•´çš„çˆ¬å–æµç¨‹
        
        æµç¨‹:
            1. Phase 1: è·å–æ‰€æœ‰é¡¹ç›®çš„åˆ—è¡¨(åç§°+é“¾æ¥) - éå†åˆ†é¡µ
            2. Phase 2: å¹¶å‘æŠ“å–æ¯ä¸ªé¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯
        
        è¿”å›:
            List[Dict]: æ‰€æœ‰é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯åˆ—è¡¨
        """
        self.start_time = time.time()
        self.results = []
        
        try:
            # Phase 1: è·å–é¡¹ç›®åˆ—è¡¨(éå†æ‰€æœ‰åˆ†é¡µ)
            self._fetch_program_list()
            
            if not self.temp_links:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•é¡¹ç›®é“¾æ¥", flush=True)
                return []
            
            # åˆå§‹åŒ–æµè§ˆå™¨æ± (Phase 2 ä½¿ç”¨)
            self.browser_pool = BrowserPool(size=self.max_workers, headless=True)
            self.browser_pool.initialize()
            
            # Phase 2: å¹¶å‘æŠ“å–è¯¦æƒ…
            self._fetch_program_details()
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†çˆ¬å–", flush=True)
        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", flush=True)
        finally:
            # å…³é—­æµè§ˆå™¨æ± 
            if self.browser_pool:
                self.browser_pool.close_all()
            self.close()
        
        self.print_summary()
        return self.results
    
    def _fetch_program_list(self) -> None:
        """
        Phase 1: ä»åˆ—è¡¨é¡µè·å–æ‰€æœ‰é¡¹ç›®çš„åç§°å’Œé“¾æ¥
        
        è¯¥æ–¹æ³•ä¼šéå†æ‰€æœ‰åˆ†é¡µ,æ”¶é›†æ‰€æœ‰é¡¹ç›®çš„åŸºæœ¬ä¿¡æ¯
        Ulster ä½¿ç”¨ start_rank å‚æ•°è¿›è¡Œåˆ†é¡µ,æ¯é¡µ40æ¡
        """
        print_phase_start(
            "Phase 1", 
            "æ­£åœ¨æ‰«æé¡¹ç›®åˆ—è¡¨(åˆ†é¡µæ¨¡å¼)...",
            total=None
        )
        print(f"   ğŸ“ ç›®æ ‡åœ°å€: {self.list_url}", flush=True)
        
        try:
            page_num = 1
            start_rank = 1
            
            while True:
                # æ„å»ºåˆ†é¡µURL
                if page_num == 1:
                    url = self.list_url
                else:
                    # æ›¿æ¢URLä¸­çš„start_rankå‚æ•°
                    url = re.sub(r'start_rank=\d+', f'start_rank={start_rank}', self.list_url)
                
                print(f"   ğŸ“„ æ­£åœ¨è®¿é—®ç¬¬ {page_num} é¡µ...", flush=True)
                
                # è®¿é—®é¡µé¢
                self.driver.get(url)
                time.sleep(2)  # ç­‰å¾…é¡µé¢åŠ è½½
                
                # ç¬¬ä¸€é¡µæ—¶éœ€è¦å¤„ç†cookie banner
                if page_num == 1:
                    self._handle_cookie_banner()
                
                # ç­‰å¾…è¯¾ç¨‹åˆ—è¡¨åŠ è½½
                try:
                    WebDriverWait(self.driver, PAGE_LOAD_WAIT).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, '.course-search-alpha__results'))
                    )
                except TimeoutException:
                    print(f"   âš ï¸ ç¬¬ {page_num} é¡µåŠ è½½è¶…æ—¶,å¯èƒ½å·²åˆ°è¾¾æœ€åä¸€é¡µ", flush=True)
                    break
                
                # æå–å½“å‰é¡µé¢çš„æ‰€æœ‰é¡¹ç›®
                before_count = len(self.temp_links)
                self._extract_programs_from_current_page()
                after_count = len(self.temp_links)
                new_count = after_count - before_count
                
                print(f"   ğŸ“„ ç¬¬ {page_num} é¡µ: å‘ç° {new_count} ä¸ªé¡¹ç›® (ç´¯è®¡: {after_count})", flush=True)
                
                # å¦‚æœæ²¡æœ‰æ–°é¡¹ç›®,è¯´æ˜å·²åˆ°è¾¾æœ€åä¸€é¡µ
                if new_count == 0:
                    print(f"   âœ… å·²åˆ°è¾¾æœ€åä¸€é¡µ", flush=True)
                    break
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
                if not self._has_next_page():
                    print(f"   âœ… å·²åˆ°è¾¾æœ€åä¸€é¡µ", flush=True)
                    break
                
                # å‡†å¤‡ä¸‹ä¸€é¡µ
                page_num += 1
                start_rank += 40  # Ulsteræ¯é¡µ40æ¡
                
                # çŸ­æš‚ä¼‘æ¯,é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(0.5)
            
            print_phase_complete("Phase 1", len(self.temp_links))
            
        except Exception as e:
            print(f"âŒ è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {e}", flush=True)
    
    def _handle_cookie_banner(self) -> None:
        """å¤„ç†Cookieæ¨ªå¹…"""
        try:
            # å°è¯•å¤šç§å¯èƒ½çš„Cookieæ¥å—æŒ‰é’®
            selectors = [
                "//button[contains(text(), 'Accept')]",
                "//button[contains(text(), 'accept')]",
                "//button[contains(@class, 'accept')]",
                "//a[contains(text(), 'Accept')]",
                "//button[@id='onetrust-accept-btn-handler']",
                "//button[contains(@class, 'cookie')]"
            ]
            
            for selector in selectors:
                try:
                    cookie_btn = WebDriverWait(self.driver, 3).until(
                        EC.element_to_be_clickable((By.XPATH, selector))
                    )
                    cookie_btn.click()
                    print("   ğŸª å·²æ¥å—Cookie", flush=True)
                    time.sleep(1)
                    return
                except TimeoutException:
                    continue
                    
        except Exception as e:
            # Cookieæ¨ªå¹…å¯èƒ½ä¸å­˜åœ¨æˆ–å·²è¢«æ¥å—
            pass
    
    def _has_next_page(self) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
        
        Ulsterçš„åˆ†é¡µæŒ‰é’®ç»“æ„:
        - æ¿€æ´»çŠ¶æ€: <a> æ ‡ç­¾,åŒ…å« <img alt="Pagination right icon">
        - ç¦ç”¨çŠ¶æ€: <div> æ ‡ç­¾,classåŒ…å« --inactive,åŒ…å« <img alt="Pagination right icon deactivated">
        """
        try:
            # æŸ¥æ‰¾åŒ…å« "Pagination right icon" çš„å³ç®­å¤´æŒ‰é’®
            # å¦‚æœæ˜¯ <a> æ ‡ç­¾,è¯´æ˜å¯ä»¥ç‚¹å‡»(æœ‰ä¸‹ä¸€é¡µ)
            # å¦‚æœæ˜¯ <div> æ ‡ç­¾,è¯´æ˜å·²ç¦ç”¨(æœ€åä¸€é¡µ)
            next_button = self.driver.find_elements(
                By.CSS_SELECTOR,
                'a.course-search-alpha__pagination__link'
            )
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ¿€æ´»çš„ä¸‹ä¸€é¡µé“¾æ¥
            for btn in next_button:
                try:
                    # æŸ¥æ‰¾åŒ…å«å³ç®­å¤´å›¾æ ‡çš„æŒ‰é’®
                    img = btn.find_element(By.CSS_SELECTOR, 'img[alt*="right"]')
                    if img and 'deactivated' not in img.get_attribute('alt').lower():
                        return True
                except NoSuchElementException:
                    continue
            
            return False
            
        except Exception:
            return False
    
    def _extract_programs_from_current_page(self) -> None:
        """
        ä»å½“å‰é¡µé¢æå–é¡¹ç›®ä¿¡æ¯
        
        Ulster ä½¿ç”¨ Funnelback æœç´¢å¼•æ“,è¯¾ç¨‹é“¾æ¥ç»“æ„:
        - é€‰æ‹©å™¨: .course-search-alpha__results__result
        - æ ‡é¢˜: .course-search-alpha__results__heading
        - é“¾æ¥: .course-search-alpha__results__result__link (Funnelbacké‡å®šå‘)
        """
        # å»é‡å¤„ç†
        seen_urls = set()
        
        # æŸ¥æ‰¾æ‰€æœ‰è¯¾ç¨‹é¡¹
        course_items = self.driver.find_elements(
            By.CSS_SELECTOR, 
            '.course-search-alpha__results__result'
        )
        
        for item in course_items:
            try:
                # è·å–è¯¾ç¨‹é“¾æ¥å…ƒç´ 
                link_elem = item.find_element(
                    By.CSS_SELECTOR, 
                    '.course-search-alpha__results__result__link'
                )
                
                # è·å–è¯¾ç¨‹åç§°
                name_elem = item.find_element(
                    By.CSS_SELECTOR,
                    '.course-search-alpha__results__heading'
                )
                name = name_elem.text.strip()
                
                if not name or len(name) < 3:
                    continue
                
                # è·å–é“¾æ¥href(è¿™æ˜¯Funnelbacké‡å®šå‘URL)
                href = link_elem.get_attribute("href")
                
                if not href:
                    continue
                
                # ä»Funnelbacké‡å®šå‘URLä¸­æå–çœŸå®URL
                real_url = self._extract_real_url(href)
                
                if not real_url or not real_url.startswith('http'):
                    continue
                
                # è·³è¿‡å·²å¤„ç†çš„URL
                if real_url in seen_urls:
                    continue
                seen_urls.add(real_url)
                
                # å»é‡æ£€æŸ¥ (ä¸å·²æœ‰åˆ—è¡¨æ¯”å¯¹)
                if not any(d['link'] == real_url for d in self.temp_links):
                    self.temp_links.append({
                        "name": name,
                        "link": real_url
                    })
                    
            except NoSuchElementException:
                continue
            except Exception:
                continue
    
    def _extract_real_url(self, url: str) -> str:
        """
        ä»é‡å®šå‘URLä¸­æå–çœŸå®çš„è¯¾ç¨‹URL
        
        Ulsterçš„æœç´¢ç»“æœé“¾æ¥æ ¼å¼:
        https://ulster-search.funnelback.squiz.cloud/s/redirect?...&url=https%3A%2F%2Fwww.ulster.ac.uk%2Fcourses%2F...
        """
        try:
            if 'funnelback' in url and '/redirect' in url:
                # è§£ææŸ¥è¯¢å‚æ•°è·å–çœŸå®URL
                parsed = urlparse(url)
                params = parse_qs(parsed.query)
                if 'url' in params:
                    return unquote(params['url'][0])
            return url
        except Exception:
            return url
    
    def _fetch_program_details(self) -> None:
        """
        Phase 2: å¹¶å‘æŠ“å–æ‰€æœ‰é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯
        
        ä½¿ç”¨è¿›åº¦ç®¡ç†å™¨å’Œæµè§ˆå™¨æ± æ‰§è¡Œå¹¶å‘ä»»åŠ¡
        """
        # åˆ›å»ºè¿›åº¦ç®¡ç†å™¨
        self.progress_manager = CrawlerProgress(max_workers=self.max_workers)
        
        # æ‰§è¡Œå¹¶å‘æŠ“å–
        self.results = self.progress_manager.run_tasks(
            items=self.temp_links,
            task_func=self._process_single_program,
            task_name="æŠ“å–è¿›åº¦",
            phase_name="Phase 2"
        )
    
    def _process_single_program(self, item: Dict) -> tuple:
        """
        å¤„ç†å•ä¸ªé¡¹ç›®çš„è¯¦æƒ…é¡µæŠ“å–
        
        ä½¿ç”¨æµè§ˆå™¨æ± å¤ç”¨æµè§ˆå™¨å®ä¾‹,æå‡æ€§èƒ½
        
        å‚æ•°:
            item (Dict): åŒ…å« name å’Œ link çš„é¡¹ç›®ä¿¡æ¯
        
        è¿”å›:
            tuple: (ç»“æœå­—å…¸, è€—æ—¶ç§’æ•°)
        """
        item_start = time.time()
        
        # åˆ›å»ºç»“æœæ¨¡æ¿
        result = self.create_result_template(item['name'], item['link'])
        
        # è®¾ç½®ç»Ÿä¸€çš„ç”³è¯·é“¾æ¥(ä»é…ç½®è¯»å–)
        result["ç”³è¯·é“¾æ¥"] = self.university_info.get("apply_register_url", "N/A")
        
        # ä»æµè§ˆå™¨æ± è·å–å®ä¾‹
        with self.browser_pool.get_browser() as driver:
            try:
                # è®¿é—®é¡¹ç›®è¯¦æƒ…é¡µ
                driver.get(item['link'])
                
                # ç­‰å¾…é¡µé¢åŠ è½½
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "main"))
                )
                
                # æŠ“å–start dateä¿¡æ¯
                result["é¡¹ç›®opendate"] = self._extract_start_date(driver)
                
                # æŠ“å–å­¦é™¢ä¿¡æ¯
                result["å­¦é™¢/å­¦ä¹ é¢†åŸŸ"] = self._extract_faculty(driver)
                
                # æŠ“å–deadlineä¿¡æ¯
                result["é¡¹ç›®deadline"] = self._extract_deadline(driver)
                
            except TimeoutException:
                # è¯¦æƒ…é¡µåŠ è½½è¶…æ—¶,ä¿æŒN/A
                pass
            except Exception:
                # å…¶ä»–é”™è¯¯,ä¿æŒN/A
                pass
        
        duration = time.time() - item_start
        return result, duration
    
    def _extract_start_date(self, driver) -> str:
        """
        æå–å¼€å§‹æ—¥æœŸ
        
        ä»è¯¾ç¨‹ä¿¡æ¯æ ä¸­æå– Start Date
        Selector: .ulster-course-info-bar__item__value
        """
        try:
            # æŸ¥æ‰¾åŒ…å« "Start Date" çš„ä¿¡æ¯é¡¹
            info_items = driver.find_elements(
                By.CSS_SELECTOR,
                '.ulster-course-info-bar__item'
            )
            
            for item in info_items:
                try:
                    label = item.find_element(By.CSS_SELECTOR, '.ulster-course-info-bar__item__label')
                    if 'start date' in label.text.lower():
                        value = item.find_element(By.CSS_SELECTOR, '.ulster-course-info-bar__item__value')
                        date_text = value.text.strip()
                        if date_text:
                            return date_text
                except NoSuchElementException:
                    continue
            
            # å¤‡ç”¨æ–¹æ¡ˆ: ç›´æ¥æŸ¥æ‰¾æ‰€æœ‰å€¼å…ƒç´ 
            try:
                values = driver.find_elements(
                    By.CSS_SELECTOR,
                    '.ulster-course-info-bar__item__value'
                )
                # é€šå¸¸Start Dateæ˜¯ç¬¬ä¸‰ä¸ªå€¼
                if len(values) >= 3:
                    return values[2].text.strip()
            except Exception:
                pass
            
            return "N/A"
            
        except Exception:
            return "N/A"
    
    def _extract_faculty(self, driver) -> str:
        """
        æå–å­¦é™¢/é™¢ç³»ä¿¡æ¯
        
        ä»è¯¾ç¨‹è¯¦æƒ…é¡µä¸­æŸ¥æ‰¾åŒ…å« Facultyã€Schoolã€College ç­‰å…³é”®è¯çš„ä¿¡æ¯
        ç­–ç•¥: 
        1. æŸ¥æ‰¾é¢åŒ…å±‘å¯¼èˆª
        2. æŸ¥æ‰¾åŒ…å«å­¦é™¢å…³é”®è¯çš„æ–‡æœ¬
        3. ä»URLè·¯å¾„æå–
        """
        try:
            # ç­–ç•¥1: ä»é¢åŒ…å±‘å¯¼èˆªæå–å­¦é™¢ä¿¡æ¯
            try:
                breadcrumbs = driver.find_elements(
                    By.CSS_SELECTOR,
                    '.breadcrumb a, nav.breadcrumb a, .ulster-breadcrumb a'
                )
                # é€šå¸¸å­¦é™¢åœ¨ç¬¬2æˆ–ç¬¬3ä¸ªä½ç½®
                for crumb in breadcrumbs[1:4]:
                    text = crumb.text.strip()
                    if text and any(keyword in text.lower() for keyword in ['faculty', 'school', 'college']):
                        return text
                # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„å­¦é™¢å…³é”®è¯ï¼Œå–ç¬¬äºŒä¸ªbreadcrumbï¼ˆé€šå¸¸æ˜¯å­¦é™¢ï¼‰
                if len(breadcrumbs) >= 2:
                    text = breadcrumbs[1].text.strip()
                    if text and len(text) > 3:
                        return text
            except Exception:
                pass
            
            # ç­–ç•¥2: æŸ¥æ‰¾åŒ…å«Faculty/Schoolå…³é”®è¯çš„å…ƒç´ 
            try:
                faculty_elements = driver.find_elements(
                    By.XPATH,
                    "//*[contains(text(), 'Faculty') or contains(text(), 'School') or contains(text(), 'College')]"
                )
                for elem in faculty_elements:
                    text = elem.text.strip()
                    # ç¡®ä¿ä¸æ˜¯å¤ªé•¿çš„æ®µè½
                    if text and 10 < len(text) < 100:
                        # è¿‡æ»¤æ‰ä¸€äº›å¸¸è§çš„éå­¦é™¢æ–‡æœ¬
                        if not any(exclude in text.lower() for exclude in ['contact', 'email', 'apply', 'deadline', 'start', '@']):
                            return text
            except Exception:
                pass
            
            # ç­–ç•¥3: ä»URLä¸­æå–å­¦é™¢ä¿¡æ¯
            try:
                url = driver.current_url
                # Ulsterçš„URLæ ¼å¼é€šå¸¸æ˜¯: /courses/201234/msc-xxx
                # æœ‰æ—¶å€™ä¼šæœ‰: /faculties/art-design-built-environment/courses/...
                if '/faculties/' in url:
                    parts = url.split('/faculties/')[1].split('/')[0]
                    # è½¬æ¢URLæ ¼å¼ä¸ºå¯è¯»æ–‡æœ¬ (ä¾‹å¦‚: art-design-built-environment -> Art Design Built Environment)
                    faculty_name = parts.replace('-', ' ').title()
                    return faculty_name
            except Exception:
                pass
            
            return "N/A"
            
        except Exception:
            return "N/A"
    
    def _extract_deadline(self, driver) -> str:
        """
        æå–ç”³è¯·æˆªæ­¢æ—¥æœŸ
        
        ä»è¯¾ç¨‹å†…å®¹ä¸­æŸ¥æ‰¾åŒ…å« "closing date" çš„æ®µè½
        Selector: .ulster-course-tabs__tabs__content p
        """
        try:
            # æŸ¥æ‰¾åŒ…å«deadlineå…³é”®è¯çš„æ®µè½
            keywords = ['closing date', 'deadline', 'application close', 'apply by']
            
            # æŸ¥æ‰¾æ‰€æœ‰æ®µè½
            paragraphs = driver.find_elements(
                By.CSS_SELECTOR,
                '.ulster-course-tabs__tabs__content p'
            )
            
            for keyword in keywords:
                for para in paragraphs:
                    text = para.text.strip()
                    if keyword in text.lower() and len(text) < 500:
                        # æ‰¾åˆ°åŒ…å«å…³é”®è¯çš„æ®µè½
                        return text
            
            # å¤‡ç”¨æ–¹æ¡ˆ: æŸ¥æ‰¾ç‰¹å®šçš„æ—¥æœŸæ¨¡å¼
            for para in paragraphs:
                text = para.text.strip()
                # æŸ¥æ‰¾ç±»ä¼¼ "28th February 2026" çš„æ—¥æœŸ
                if re.search(r'\d{1,2}(st|nd|rd|th)?\s+(January|February|March|April|May|June|July|August|September|October|November|December)\s+\d{4}', text):
                    if len(text) < 500:
                        return text
            
            return "N/A"
            
        except Exception:
            return "N/A"


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    with UlsterSpider(headless=False) as spider:
        results = spider.run()
        
        print(f"\næŠ“å–å®Œæˆ,å…± {len(results)} ä¸ªé¡¹ç›®")
        if results:
            import json
            print("\nå‰3ä¸ªé¡¹ç›®ç¤ºä¾‹:")
            print(json.dumps(results[:3], indent=2, ensure_ascii=False))
