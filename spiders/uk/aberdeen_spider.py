# -*- coding: utf-8 -*-
"""
é˜¿ä¼¯ä¸å¤§å­¦ (University of Aberdeen) çˆ¬è™«æ¨¡å—
è´Ÿè´£æŠ“å– Aberdeen Postgraduate Taught é¡¹ç›®ä¿¡æ¯
"""

import time
from typing import List, Dict
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from spiders.base_spider import BaseSpider
from utils.progress import CrawlerProgress, print_phase_start, print_phase_complete
from utils.selenium_utils import BrowserPool
from config import MAX_WORKERS, PAGE_LOAD_WAIT


class AberdeenSpider(BaseSpider):
    """
    é˜¿ä¼¯ä¸å¤§å­¦çˆ¬è™«
    
    è´Ÿè´£ä» University of Aberdeen å®˜ç½‘çˆ¬å–æ‰€æœ‰ Postgraduate Taught é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯,åŒ…æ‹¬:
    - é¡¹ç›®åç§°
    - é¡¹ç›®é“¾æ¥
    - ç”³è¯·æˆªæ­¢æ—¥æœŸ(å¦‚æœæœ‰)
    - ç»Ÿä¸€çš„ç”³è¯·æ³¨å†Œå’Œç™»å½•é“¾æ¥
    
    ä½¿ç”¨ç¤ºä¾‹:
        >>> with AberdeenSpider() as spider:
        ...     data = spider.run()
        ...     print(f"çˆ¬å–äº† {len(data)} æ¡æ•°æ®")
    """
    
    def __init__(self, headless: bool = True, max_workers: int = None):
        """
        åˆå§‹åŒ– Aberdeen çˆ¬è™«
        
        å‚æ•°:
            headless (bool): æ˜¯å¦æ— å¤´æ¨¡å¼è¿è¡Œ
            max_workers (int): å¹¶å‘çº¿ç¨‹æ•°,å¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨ config.py ä¸­çš„é…ç½®
        """
        super().__init__("aberdeen", headless)
        from config import MAX_WORKERS as CONFIG_MAX_WORKERS
        self.max_workers = max_workers if max_workers is not None else CONFIG_MAX_WORKERS
        self.temp_links: List[Dict] = []  # ä¸´æ—¶å­˜å‚¨é¡¹ç›®é“¾æ¥åˆ—è¡¨
        self.progress_manager: CrawlerProgress = None  # è¿›åº¦ç®¡ç†å™¨
        self.browser_pool: BrowserPool = None  # æµè§ˆå™¨æ± 
    
    def run(self) -> List[Dict]:
        """
        æ‰§è¡Œå®Œæ•´çš„çˆ¬å–æµç¨‹
        
        æµç¨‹:
            1. Phase 1: è·å–æ‰€æœ‰é¡¹ç›®çš„åˆ—è¡¨(åç§°+é“¾æ¥) - ä½¿ç”¨ limit=All
            2. Phase 2: å¹¶å‘æŠ“å–æ¯ä¸ªé¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯
        
        è¿”å›:
            List[Dict]: æ‰€æœ‰é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯åˆ—è¡¨
        """
        self.start_time = time.time()
        self.results = []
        
        try:
            # Phase 1: è·å–é¡¹ç›®åˆ—è¡¨(ä¸€æ¬¡æ€§è·å–å…¨éƒ¨)
            self._fetch_program_list()
            
            if not self.temp_links:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•é¡¹ç›®é“¾æ¥")
                return []
            
            # åˆå§‹åŒ–æµè§ˆå™¨æ± (Phase 2 ä½¿ç”¨)
            self.browser_pool = BrowserPool(size=self.max_workers, headless=True)
            self.browser_pool.initialize()
            
            # Phase 2: å¹¶å‘æŠ“å–è¯¦æƒ…
            self._fetch_program_details()
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†çˆ¬å–")
        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            # å…³é—­æµè§ˆå™¨æ± 
            if self.browser_pool:
                self.browser_pool.close_all()
            self.close()
        
        self.print_summary()
        return self.results
    
    def _fetch_program_list(self) -> None:
        """
        Phase 1: ä»åˆ—è¡¨é¡µè·å–æ‰€æœ‰é¡¹ç›®çš„åç§°å’Œé“¾æ¥
        
        è¯¥æ–¹æ³•ä½¿ç”¨ limit=All å‚æ•°ä¸€æ¬¡æ€§è·å–æ‰€æœ‰é¡¹ç›®
        Aberdeen ç½‘ç«™çš„åˆ—è¡¨é¡µä½¿ç”¨è¡¨æ ¼å±•ç¤º,æ¯è¡ŒåŒ…å«é¡¹ç›®åç§°å’Œé“¾æ¥
        """
        print_phase_start(
            "Phase 1", 
            "æ­£åœ¨æ‰«æé¡¹ç›®åˆ—è¡¨...",
            total=None
        )
        print(f"   ğŸ“ ç›®æ ‡åœ°å€: {self.list_url}")
        
        try:
            # è®¿é—®é¡µé¢
            self.driver.get(self.list_url)
            time.sleep(3)  # ç­‰å¾…é¡µé¢åŠ è½½
            
            # å¤„ç†å¯èƒ½çš„Cookieæ¨ªå¹…
            self._handle_cookie_banner()
            
            # ç­‰å¾…è¡¨æ ¼åŠ è½½
            try:
                WebDriverWait(self.driver, PAGE_LOAD_WAIT).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, 'table.programme-list, .degree-listing, table'))
                )
            except TimeoutException:
                print("   âš ï¸ è¡¨æ ¼åŠ è½½è¶…æ—¶,å°è¯•ç»§ç»­...")
            
            # æå–æ‰€æœ‰é¡¹ç›®
            self._extract_programs_from_page()
            
            print_phase_complete("Phase 1", len(self.temp_links))
            
        except Exception as e:
            print(f"âŒ è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {e}")
    
    def _handle_cookie_banner(self) -> None:
        """å¤„ç†Cookieæ¨ªå¹…"""
        try:
            # å°è¯•å¤šç§å¯èƒ½çš„Cookieæ¥å—æŒ‰é’®
            selectors = [
                "//button[contains(text(), 'Accept')]",
                "//button[contains(text(), 'accept')]",
                "//button[contains(@class, 'accept')]",
                "//a[contains(text(), 'Accept')]",
                "//button[@id='onetrust-accept-btn-handler']",
                "//button[contains(text(), 'OK')]",
                "//button[contains(text(), 'Agree')]"
            ]
            
            for selector in selectors:
                try:
                    cookie_btn = WebDriverWait(self.driver, 3).until(
                        EC.element_to_be_clickable((By.XPATH, selector))
                    )
                    cookie_btn.click()
                    print("   ğŸª å·²æ¥å—Cookie")
                    time.sleep(1)
                    return
                except TimeoutException:
                    continue
                    
        except Exception:
            # Cookieæ¨ªå¹…å¯èƒ½ä¸å­˜åœ¨æˆ–å·²è¢«æ¥å—
            pass
    
    def _extract_programs_from_page(self) -> None:
        """
        ä»å½“å‰é¡µé¢æå–é¡¹ç›®ä¿¡æ¯
        
        Aberdeen ä½¿ç”¨è¡¨æ ¼å±•ç¤ºé¡¹ç›®åˆ—è¡¨,æ¯è¡ŒåŒ…å«:
        - é¡¹ç›®åç§°(é“¾æ¥)
        - å­¦ä½ç±»å‹
        - å­¦ä¹ ç±»å‹
        """
        # å»é‡å¤„ç†
        seen_urls = set()
        
        # æ–¹æ³•1: æŸ¥æ‰¾è¡¨æ ¼ä¸­çš„é¡¹ç›®é“¾æ¥
        # Aberdeen ç½‘ç«™è¡¨æ ¼ä¸­é¡¹ç›®é“¾æ¥æ ¼å¼: /study/postgraduate-taught/degree-programmes/{id}/{name}/
        program_selectors = [
            'table tbody tr td a[href*="/degree-programmes/"]',
            'a[href*="/study/postgraduate-taught/degree-programmes/"]',
            '.programme-list a[href*="/degree-programmes/"]',
            'table a[href*="/degree-programmes/"]'
        ]
        
        course_links = []
        for selector in program_selectors:
            course_links = self.driver.find_elements(By.CSS_SELECTOR, selector)
            if course_links:
                break
        
        print(f"   ğŸ“Š å‘ç° {len(course_links)} ä¸ªé“¾æ¥å…ƒç´ ")
        
        for link in course_links:
            try:
                # è·å–è¯¾ç¨‹åç§°
                name = link.text.strip()
                href = link.get_attribute("href")
                
                if not name or len(name) < 3:
                    continue
                    
                if not href:
                    continue
                
                # è¿‡æ»¤æ— æ•ˆçš„é“¾æ¥
                if '/degree-programmes/' not in href:
                    continue
                
                # è¿‡æ»¤åˆ†é¡µå’Œæ’åºé“¾æ¥
                if '?page=' in href or '?limit=' in href or '?order_by=' in href or '?direction=' in href:
                    continue
                    
                # è¿‡æ»¤å¯¼èˆªé“¾æ¥
                invalid_texts = ['next', 'previous', 'view all', 'simple view', 'detailed view', 
                                '1', '2', '3', '4', '5', '6', '7', '8', 'â†’', 'â†', '>>', '<<']
                if name.lower() in invalid_texts:
                    continue
                
                # è·³è¿‡å·²å¤„ç†çš„URL
                if href in seen_urls:
                    continue
                seen_urls.add(href)
                
                # ç¡®ä¿URLæ ¼å¼æ­£ç¡®
                if not href.startswith('http'):
                    href = f"{self.base_url}{href}" if not href.startswith('/') else f"{self.base_url}{href}"
                
                # å»é‡æ£€æŸ¥ (ä¸å·²æœ‰åˆ—è¡¨æ¯”å¯¹)
                if not any(d['link'] == href for d in self.temp_links):
                    self.temp_links.append({
                        "name": name,
                        "link": href
                    })
                    
            except Exception:
                continue
    
    def _fetch_program_details(self) -> None:
        """
        Phase 2: å¹¶å‘æŠ“å–æ‰€æœ‰é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯
        
        ä½¿ç”¨è¿›åº¦ç®¡ç†å™¨å’Œæµè§ˆå™¨æ± æ‰§è¡Œå¹¶å‘ä»»åŠ¡
        """
        # åˆ›å»ºè¿›åº¦ç®¡ç†å™¨
        self.progress_manager = CrawlerProgress(max_workers=self.max_workers)
        
        # æ‰§è¡Œå¹¶å‘æŠ“å–
        self.results = self.progress_manager.run_tasks(
            items=self.temp_links,
            task_func=self._process_single_program,
            task_name="æŠ“å–è¿›åº¦",
            phase_name="Phase 2"
        )
    
    def _process_single_program(self, item: Dict) -> tuple:
        """
        å¤„ç†å•ä¸ªé¡¹ç›®çš„è¯¦æƒ…é¡µæŠ“å–
        
        ä½¿ç”¨æµè§ˆå™¨æ± å¤ç”¨æµè§ˆå™¨å®ä¾‹,æå‡æ€§èƒ½
        
        å‚æ•°:
            item (Dict): åŒ…å« name å’Œ link çš„é¡¹ç›®ä¿¡æ¯
        
        è¿”å›:
            tuple: (ç»“æœå­—å…¸, è€—æ—¶ç§’æ•°)
        """
        item_start = time.time()
        
        # åˆ›å»ºç»“æœæ¨¡æ¿
        result = self.create_result_template(item['name'], item['link'])
        
        # è®¾ç½®ç»Ÿä¸€çš„ç”³è¯·é“¾æ¥(ä»é…ç½®è¯»å–)
        result["ç”³è¯·é“¾æ¥"] = self.university_info.get("apply_register_url", "N/A")
        
        # ä»æµè§ˆå™¨æ± è·å–å®ä¾‹
        with self.browser_pool.get_browser() as driver:
            try:
                # è®¿é—®é¡¹ç›®è¯¦æƒ…é¡µ
                driver.get(item['link'])
                
                # ç­‰å¾…é¡µé¢åŠ è½½
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "main"))
                )
                
                # æŠ“å–deadlineä¿¡æ¯
                result["é¡¹ç›®deadline"] = self._extract_deadline(driver)
                
                # å°è¯•æŠ“å–å¼€æ”¾æ—¥æœŸ
                result["é¡¹ç›®opendate"] = self._extract_open_date(driver)
                
            except TimeoutException:
                # è¯¦æƒ…é¡µåŠ è½½è¶…æ—¶,ä¿æŒN/A
                pass
            except Exception:
                # å…¶ä»–é”™è¯¯,ä¿æŒN/A
                pass
        
        duration = time.time() - item_start
        return result, duration
    
    def _extract_deadline(self, driver) -> str:
        """
        æå–ç”³è¯·æˆªæ­¢æ—¥æœŸ
        """
        try:
            # æŸ¥æ‰¾åŒ…å«deadlineå…³é”®è¯çš„å…ƒç´ 
            keywords = ['deadline', 'closing date', 'application close', 'apply by', 'applications close']
            
            for keyword in keywords:
                try:
                    elements = driver.find_elements(
                        By.XPATH, 
                        f"//*[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{keyword}')]"
                    )
                    
                    for elem in elements:
                        text = elem.text.strip()
                        if text and len(text) > 5 and len(text) < 500:
                            # å°è¯•æ‰¾åˆ°æ—¥æœŸä¿¡æ¯
                            parent = elem.find_element(By.XPATH, "./..")
                            parent_text = parent.text.strip()
                            if parent_text and len(parent_text) < 500:
                                return parent_text
                            return text
                            
                except NoSuchElementException:
                    continue
            
            # å¤‡ç”¨æ–¹æ¡ˆ: æŸ¥æ‰¾ "How to apply" æˆ– "Apply" éƒ¨åˆ†
            try:
                apply_section = driver.find_element(
                    By.XPATH, 
                    "//h2[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'apply')]/.."
                )
                section_text = apply_section.text
                
                lines = section_text.split('\n')
                for line in lines:
                    if 'deadline' in line.lower() or 'date' in line.lower():
                        return line.strip()
                        
            except NoSuchElementException:
                pass
            
            return "N/A"
            
        except Exception:
            return "N/A"
    
    def _extract_open_date(self, driver) -> str:
        """
        æå–ç”³è¯·å¼€æ”¾æ—¥æœŸ
        """
        try:
            keywords = ['open date', 'opening date', 'applications open', 'apply from', 'start date']
            
            for keyword in keywords:
                try:
                    elements = driver.find_elements(
                        By.XPATH, 
                        f"//*[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{keyword}')]"
                    )
                    
                    for elem in elements:
                        text = elem.text.strip()
                        if text and len(text) > 5 and len(text) < 300:
                            return text
                            
                except NoSuchElementException:
                    continue
            
            return "N/A"
            
        except Exception:
            return "N/A"


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    with AberdeenSpider(headless=False) as spider:
        results = spider.run()
        
        print(f"\næŠ“å–å®Œæˆ,å…± {len(results)} ä¸ªé¡¹ç›®")
        if results:
            import json
            print("\nå‰3ä¸ªé¡¹ç›®ç¤ºä¾‹:")
            print(json.dumps(results[:3], indent=2, ensure_ascii=False))
