# -*- coding: utf-8 -*-
"""
æ–¯ç‰¹æ‹‰æ–¯å…‹è±å¾·å¤§å­¦ (University of Strathclyde) çˆ¬è™«æ¨¡å—
è´Ÿè´£æŠ“å– Strathclyde Postgraduate Taught é¡¹ç›®ä¿¡æ¯
"""

import time
from typing import List, Dict
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from spiders.base_spider import BaseSpider
from utils.progress import CrawlerProgress, print_phase_start, print_phase_complete
from utils.selenium_utils import BrowserPool
from config import MAX_WORKERS, PAGE_LOAD_WAIT


class StrathclydeSpider(BaseSpider):
    """
    æ–¯ç‰¹æ‹‰æ–¯å…‹è±å¾·å¤§å­¦çˆ¬è™«
    
    è´Ÿè´£ä» University of Strathclyde å®˜ç½‘çˆ¬å–æ‰€æœ‰ Postgraduate Taught é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯,åŒ…æ‹¬:
    - é¡¹ç›®åç§°
    - é¡¹ç›®é“¾æ¥
    - è¯¾ç¨‹å¼€å§‹æ—¥æœŸ
    - ç»Ÿä¸€çš„ç”³è¯·æ³¨å†Œå’Œç™»å½•é“¾æ¥
    
    ç½‘ç«™ç‰¹ç‚¹:
    - ä½¿ç”¨æ— é™æ»šåŠ¨åŠ è½½è¯¾ç¨‹åˆ—è¡¨
    - çº¦ 239 ä¸ªç ”ç©¶ç”Ÿæˆè¯¾é¡¹ç›®
    
    ä½¿ç”¨ç¤ºä¾‹:
        >>> with StrathclydeSpider() as spider:
        ...     data = spider.run()
        ...     print(f"çˆ¬å–äº† {len(data)} æ¡æ•°æ®")
    """
    
    def __init__(self, headless: bool = True, max_workers: int = None):
        """
        åˆå§‹åŒ– Strathclyde çˆ¬è™«
        
        å‚æ•°:
            headless (bool): æ˜¯å¦æ— å¤´æ¨¡å¼è¿è¡Œ
            max_workers (int): å¹¶å‘çº¿ç¨‹æ•°,å¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨ config.py ä¸­çš„é…ç½®
        """
        super().__init__("strathclyde", headless)
        from config import MAX_WORKERS as CONFIG_MAX_WORKERS
        self.max_workers = max_workers if max_workers is not None else CONFIG_MAX_WORKERS
        self.temp_links: List[Dict] = []  # ä¸´æ—¶å­˜å‚¨é¡¹ç›®é“¾æ¥åˆ—è¡¨
        self.progress_manager: CrawlerProgress = None  # è¿›åº¦ç®¡ç†å™¨
        self.browser_pool: BrowserPool = None  # æµè§ˆå™¨æ± 
    
    def run(self) -> List[Dict]:
        """
        æ‰§è¡Œå®Œæ•´çš„çˆ¬å–æµç¨‹
        
        æµç¨‹:
            1. Phase 1: è·å–æ‰€æœ‰é¡¹ç›®çš„åˆ—è¡¨(åç§°+é“¾æ¥) - é€šè¿‡æ— é™æ»šåŠ¨åŠ è½½
            2. Phase 2: å¹¶å‘æŠ“å–æ¯ä¸ªé¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯
        
        è¿”å›:
            List[Dict]: æ‰€æœ‰é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯åˆ—è¡¨
        """
        self.start_time = time.time()
        self.results = []
        
        try:
            # Phase 1: è·å–é¡¹ç›®åˆ—è¡¨(é€šè¿‡æ— é™æ»šåŠ¨)
            self._fetch_program_list()
            
            if not self.temp_links:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•é¡¹ç›®é“¾æ¥")
                return []
            
            # åˆå§‹åŒ–æµè§ˆå™¨æ± (Phase 2 ä½¿ç”¨)
            self.browser_pool = BrowserPool(size=self.max_workers, headless=True)
            self.browser_pool.initialize()
            
            # Phase 2: å¹¶å‘æŠ“å–è¯¦æƒ…
            self._fetch_program_details()
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†çˆ¬å–")
        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            # å…³é—­æµè§ˆå™¨æ± 
            if self.browser_pool:
                self.browser_pool.close_all()
            self.close()
        
        self.print_summary()
        return self.results
    
    def _fetch_program_list(self) -> None:
        """
        Phase 1: ä»åˆ—è¡¨é¡µè·å–æ‰€æœ‰é¡¹ç›®çš„åç§°å’Œé“¾æ¥
        
        è¯¥æ–¹æ³•é€šè¿‡æ— é™æ»šåŠ¨åŠ è½½æ‰€æœ‰è¯¾ç¨‹
        Strathclyde ç½‘ç«™ä½¿ç”¨æ— é™æ»šåŠ¨,éœ€è¦æŒç»­æ»šåŠ¨ç›´åˆ°æ‰€æœ‰è¯¾ç¨‹åŠ è½½å®Œæˆ
        """
        print_phase_start(
            "Phase 1", 
            "æ­£åœ¨æ‰«æé¡¹ç›®åˆ—è¡¨ (æ— é™æ»šåŠ¨)...",
            total=None
        )
        print(f"   ğŸ“ ç›®æ ‡åœ°å€: {self.list_url}")
        
        try:
            # è®¿é—®é¡µé¢
            self.driver.get(self.list_url)
            time.sleep(3)  # ç­‰å¾…é¡µé¢åŠ è½½
            
            # å¤„ç† Cookie æ¨ªå¹…
            self._handle_cookie_banner()
            
            # ç­‰å¾…è¯¾ç¨‹åˆ—è¡¨åŠ è½½
            try:
                WebDriverWait(self.driver, PAGE_LOAD_WAIT).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, '.course-search-result__link'))
                )
            except TimeoutException:
                print("   âš ï¸ è¯¾ç¨‹åˆ—è¡¨åŠ è½½è¶…æ—¶,å°è¯•ç»§ç»­...")
            
            # æ‰§è¡Œæ— é™æ»šåŠ¨åŠ è½½æ‰€æœ‰è¯¾ç¨‹
            self._scroll_to_load_all()
            
            # æå–æ‰€æœ‰é¡¹ç›®
            self._extract_programs_from_page()
            
            print_phase_complete("Phase 1", len(self.temp_links))
            
        except Exception as e:
            print(f"âŒ è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {e}")
    
    def _handle_cookie_banner(self) -> None:
        """å¤„ç† Cookie æ¨ªå¹…"""
        try:
            # æ–¹æ³•1: ä½¿ç”¨ JavaScript ç›´æ¥ç‚¹å‡»æ¥å—æŒ‰é’®
            try:
                self.driver.execute_script("""
                    // å°è¯•ç‚¹å‡»æ¥å—æŒ‰é’®
                    var acceptBtns = document.querySelectorAll('button');
                    for (var i = 0; i < acceptBtns.length; i++) {
                        var text = acceptBtns[i].innerText.toLowerCase();
                        if (text.includes('accept') || text.includes('agree') || text.includes('ok')) {
                            acceptBtns[i].click();
                            return true;
                        }
                    }
                    return false;
                """)
                time.sleep(1)
            except:
                pass
            
            # æ–¹æ³•2: ä½¿ç”¨ JavaScript ç§»é™¤/éšè— overlay
            try:
                self.driver.execute_script("""
                    // ç§»é™¤ cookie overlay
                    var overlays = document.querySelectorAll('[id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"]');
                    overlays.forEach(function(o) {
                        o.style.display = 'none';
                    });
                    
                    // æ¢å¤ body æ»šåŠ¨
                    document.body.style.overflow = 'auto';
                """)
                print("   ğŸª å·²å¤„ç† Cookie å¼¹çª—")
            except:
                pass
                    
        except Exception:
            # Cookie æ¨ªå¹…å¯èƒ½ä¸å­˜åœ¨æˆ–å·²è¢«æ¥å—
            pass
    
    def _scroll_to_load_all(self) -> None:
        """
        é€šè¿‡æ— é™æ»šåŠ¨åŠ è½½æ‰€æœ‰è¯¾ç¨‹
        
        æŒç»­æ»šåŠ¨ç›´åˆ°æ²¡æœ‰æ–°è¯¾ç¨‹åŠ è½½
        """
        print("   ğŸ“œ æ­£åœ¨æ‰§è¡Œæ— é™æ»šåŠ¨åŠ è½½...")
        
        last_count = 0
        scroll_attempts = 0
        max_attempts = 50  # æœ€å¤§æ»šåŠ¨æ¬¡æ•°,é˜²æ­¢æ— é™å¾ªç¯
        no_change_count = 0
        
        while scroll_attempts < max_attempts:
            # æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1.5)  # ç­‰å¾…åŠ è½½
            
            # è·å–å½“å‰è¯¾ç¨‹æ•°é‡
            current_count = len(self.driver.find_elements(By.CSS_SELECTOR, '.course-search-result__link'))
            
            if current_count == last_count:
                no_change_count += 1
                if no_change_count >= 3:
                    # è¿ç»­3æ¬¡æ²¡æœ‰å˜åŒ–,è®¤ä¸ºåŠ è½½å®Œæˆ
                    print(f"   âœ… æ»šåŠ¨åŠ è½½å®Œæˆ,å…±åŠ è½½ {current_count} ä¸ªè¯¾ç¨‹")
                    break
            else:
                no_change_count = 0
                print(f"   ğŸ“Š å·²åŠ è½½ {current_count} ä¸ªè¯¾ç¨‹...", end='\r')
            
            last_count = current_count
            scroll_attempts += 1
        
        if scroll_attempts >= max_attempts:
            print(f"   âš ï¸ è¾¾åˆ°æœ€å¤§æ»šåŠ¨æ¬¡æ•°,å·²åŠ è½½ {last_count} ä¸ªè¯¾ç¨‹")
    
    def _extract_programs_from_page(self) -> None:
        """
        ä»å½“å‰é¡µé¢æå–é¡¹ç›®ä¿¡æ¯
        
        Strathclyde ä½¿ç”¨ .course-search-result__link å±•ç¤ºé¡¹ç›®åˆ—è¡¨
        æ ‡é¢˜åœ¨é“¾æ¥å†…çš„ h2 å…ƒç´ ä¸­
        """
        # å»é‡å¤„ç†
        seen_urls = set()
        
        # æŸ¥æ‰¾æ‰€æœ‰è¯¾ç¨‹é“¾æ¥
        course_links = self.driver.find_elements(By.CSS_SELECTOR, '.course-search-result__link')
        
        print(f"   ğŸ“Š å‘ç° {len(course_links)} ä¸ªè¯¾ç¨‹é“¾æ¥")
        
        extracted_count = 0
        errors_count = 0
        
        for link in course_links:
            try:
                # è·å–é“¾æ¥ URL
                href = link.get_attribute("href")
                
                if not href:
                    continue
                
                # è¿‡æ»¤éç ”ç©¶ç”Ÿè¯¾ç¨‹é“¾æ¥
                if '/courses/postgraduatetaught/' not in href:
                    continue
                
                # è·å–è¯¾ç¨‹åç§° - åªä» h2 å…ƒç´ æå–æ ‡é¢˜
                try:
                    title_elem = link.find_element(By.CSS_SELECTOR, 'h2')
                    name = title_elem.text.strip()
                except NoSuchElementException:
                    # å¦‚æœæ‰¾ä¸åˆ° h2ï¼Œå›é€€åˆ°é“¾æ¥çš„ç¬¬ä¸€è¡Œæ–‡æœ¬
                    full_text = link.text.strip()
                    name = full_text.split('\n')[0].strip() if full_text else ""
                except Exception as e:
                    errors_count += 1
                    continue
                
                if not name or len(name) < 3:
                    continue
                
                # è·³è¿‡å·²å¤„ç†çš„ URL
                if href in seen_urls:
                    continue
                seen_urls.add(href)
                
                # ç¡®ä¿ URL æ ¼å¼æ­£ç¡®
                if not href.startswith('http'):
                    href = f"{self.base_url}{href}"
                
                self.temp_links.append({
                    "name": name,
                    "link": href
                })
                extracted_count += 1
                    
            except Exception as e:
                errors_count += 1
                continue
        
        if errors_count > 0:
            print(f"   âš ï¸ æå–æ—¶å‘ç”Ÿ {errors_count} ä¸ªé”™è¯¯")
        print(f"   âœ… æˆåŠŸæå– {extracted_count} ä¸ªç ”ç©¶ç”Ÿé¡¹ç›®")
    
    def _fetch_program_details(self) -> None:
        """
        Phase 2: å¹¶å‘æŠ“å–æ‰€æœ‰é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯
        
        ä½¿ç”¨è¿›åº¦ç®¡ç†å™¨å’Œæµè§ˆå™¨æ± æ‰§è¡Œå¹¶å‘ä»»åŠ¡
        """
        # åˆ›å»ºè¿›åº¦ç®¡ç†å™¨
        self.progress_manager = CrawlerProgress(max_workers=self.max_workers)
        
        # æ‰§è¡Œå¹¶å‘æŠ“å–
        self.results = self.progress_manager.run_tasks(
            items=self.temp_links,
            task_func=self._process_single_program,
            task_name="æŠ“å–è¿›åº¦",
            phase_name="Phase 2"
        )
    
    def _process_single_program(self, item: Dict) -> tuple:
        """
        å¤„ç†å•ä¸ªé¡¹ç›®çš„è¯¦æƒ…é¡µæŠ“å–
        
        ä½¿ç”¨æµè§ˆå™¨æ± å¤ç”¨æµè§ˆå™¨å®ä¾‹,æå‡æ€§èƒ½
        
        å‚æ•°:
            item (Dict): åŒ…å« name å’Œ link çš„é¡¹ç›®ä¿¡æ¯
        
        è¿”å›:
            tuple: (ç»“æœå­—å…¸, è€—æ—¶ç§’æ•°)
        """
        item_start = time.time()
        
        # åˆ›å»ºç»“æœæ¨¡æ¿
        result = self.create_result_template(item['name'], item['link'])
        
        # è®¾ç½®ç»Ÿä¸€çš„ç”³è¯·é“¾æ¥(ä»é…ç½®è¯»å–)
        result["ç”³è¯·é“¾æ¥"] = self.university_info.get("apply_register_url", "N/A")
        
        # ä»æµè§ˆå™¨æ± è·å–å®ä¾‹
        with self.browser_pool.get_browser() as driver:
            try:
                # è®¿é—®é¡¹ç›®è¯¦æƒ…é¡µ
                driver.get(item['link'])
                
                # ç­‰å¾…é¡µé¢åŠ è½½
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "h1"))
                )
                
                # æŠ“å–å¼€å§‹æ—¥æœŸä½œä¸º opendate
                result["é¡¹ç›®opendate"] = self._extract_start_date(driver)
                
                # å°è¯•æŠ“å– deadline ä¿¡æ¯
                result["é¡¹ç›®deadline"] = self._extract_deadline(driver)
                
            except TimeoutException:
                # è¯¦æƒ…é¡µåŠ è½½è¶…æ—¶,ä¿æŒ N/A
                pass
            except Exception:
                # å…¶ä»–é”™è¯¯,ä¿æŒ N/A
                pass
        
        duration = time.time() - item_start
        return result, duration
    
    def _extract_start_date(self, driver) -> str:
        """
        æå–è¯¾ç¨‹å¼€å§‹æ—¥æœŸ
        
        Strathclyde çš„è¯¾ç¨‹å¼€å§‹æ—¥æœŸé€šå¸¸åœ¨ Key Facts åŒºåŸŸ
        """
        try:
            # æ–¹æ³•1: æŸ¥æ‰¾ Key Facts ä¸­çš„å¼€å§‹æ—¥æœŸ
            key_facts = driver.find_elements(By.CSS_SELECTOR, '.key-fact__text')
            
            for fact in key_facts:
                text = fact.text.strip()
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æœˆä»½ä¿¡æ¯
                months = ['January', 'February', 'March', 'April', 'May', 'June', 
                         'July', 'August', 'September', 'October', 'November', 'December']
                for month in months:
                    if month in text:
                        return text
            
            # æ–¹æ³•2: æŸ¥æ‰¾åŒ…å« "Start" çš„å…ƒç´ 
            start_elements = driver.find_elements(
                By.XPATH, 
                "//*[contains(text(), 'Start')]"
            )
            
            for elem in start_elements:
                try:
                    parent = elem.find_element(By.XPATH, "./..")
                    text = parent.text.strip()
                    if any(month in text for month in months):
                        # æå–æ—¥æœŸéƒ¨åˆ†
                        lines = text.split('\n')
                        for line in lines:
                            if any(month in line for month in months):
                                return line.strip()
                except:
                    continue
            
            return "N/A"
            
        except Exception:
            return "N/A"
    
    def _extract_deadline(self, driver) -> str:
        """
        æå–ç”³è¯·æˆªæ­¢æ—¥æœŸ
        
        ä¼˜åŒ–ç­–ç•¥:
        1. æŸ¥æ‰¾åŒ…å« deadline å…³é”®è¯çš„å…ƒç´ 
        2. æ£€æŸ¥çˆ¶å®¹å™¨è·å–å®Œæ•´ä¿¡æ¯ (åŒ…å«æ ‡ç­¾å’Œæ—¥æœŸå€¼)
        3. å¦‚æœçˆ¶å®¹å™¨ä¸ºç©ºï¼Œå°è¯•è·å–ç›¸é‚»å…ƒç´ 
        """
        try:
            # æŸ¥æ‰¾åŒ…å« deadline å…³é”®è¯çš„å…ƒç´ 
            keywords = ['deadline', 'closing date', 'application close', 'apply by']
            
            for keyword in keywords:
                try:
                    elements = driver.find_elements(
                        By.XPATH, 
                        f"//*[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{keyword}')]"
                    )
                    
                    for elem in elements:
                        # ç­–ç•¥1: å°è¯•è·å–çˆ¶å®¹å™¨çš„æ–‡æœ¬ (é€šå¸¸åŒ…å«æ ‡ç­¾+å€¼)
                        try:
                            parent = elem.find_element(By.XPATH, "./..")
                            parent_text = parent.text.strip()
                            
                            # å¦‚æœçˆ¶å®¹å™¨æ–‡æœ¬æ¯”å½“å‰å…ƒç´ æ–‡æœ¬é•¿ï¼Œè¯´æ˜åŒ…å«äº†æ›´å¤šä¿¡æ¯
                            if parent_text and len(parent_text) > len(elem.text.strip()):
                                # æ£€æŸ¥æ˜¯å¦åŒ…å«æœˆä»½ç­‰æ—¥æœŸä¿¡æ¯
                                months = ['January', 'February', 'March', 'April', 'May', 'June', 
                                         'July', 'August', 'September', 'October', 'November', 'December',
                                         'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 
                                         'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
                                
                                if any(month in parent_text for month in months):
                                    # æ¸…ç†æ¢è¡Œç¬¦
                                    return parent_text.replace('\n', ' ').strip()
                        except:
                            pass
                        
                        # ç­–ç•¥2: å¦‚æœå…ƒç´ æœ¬èº«æ–‡æœ¬åˆç†ï¼Œç›´æ¥è¿”å›
                        elem_text = elem.text.strip()
                        if elem_text and len(elem_text) > 5 and len(elem_text) < 500:
                            return elem_text
                            
                except NoSuchElementException:
                    continue
            
            return "N/A"
            
        except Exception:
            return "N/A"


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    with StrathclydeSpider(headless=False) as spider:
        results = spider.run()
        
        print(f"\næŠ“å–å®Œæˆ,å…± {len(results)} ä¸ªé¡¹ç›®")
        if results:
            import json
            print("\nå‰3ä¸ªé¡¹ç›®ç¤ºä¾‹:")
            print(json.dumps(results[:3], indent=2, ensure_ascii=False))
