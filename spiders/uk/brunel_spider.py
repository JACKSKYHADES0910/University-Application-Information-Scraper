# -*- coding: utf-8 -*-
"""
ä¼¦æ•¦å¸ƒé²å†…å°”å¤§å­¦ (Brunel University London) çˆ¬è™«æ¨¡å—
è´Ÿè´£æŠ“å– Brunel Postgraduate Taught é¡¹ç›®ä¿¡æ¯
"""

import time
from typing import List, Dict
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException

from spiders.base_spider import BaseSpider
from utils.progress import CrawlerProgress, print_phase_start, print_phase_complete
from utils.selenium_utils import BrowserPool
from config import MAX_WORKERS, PAGE_LOAD_WAIT


class BrunelSpider(BaseSpider):
    """
    ä¼¦æ•¦å¸ƒé²å†…å°”å¤§å­¦çˆ¬è™«
    
    è´Ÿè´£ä» Brunel University London å®˜ç½‘çˆ¬å–æ‰€æœ‰ Postgraduate Taught é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯,åŒ…æ‹¬:
    - é¡¹ç›®åç§°
    - é¡¹ç›®é“¾æ¥
    - è¯¾ç¨‹å¼€å§‹æ—¥æœŸ
    - å…·ä½“çš„ç”³è¯·é“¾æ¥ (ä» Apply now æŠ˜å èœå•ä¸­æå–ç¬¬ä¸€ä¸ª)
    """
    
    def __init__(self, headless: bool = True, max_workers: int = None):
        """
        åˆå§‹åŒ– Brunel çˆ¬è™«
        """
        super().__init__("brunel", headless)
        from config import MAX_WORKERS as CONFIG_MAX_WORKERS
        self.max_workers = max_workers if max_workers is not None else CONFIG_MAX_WORKERS
        self.temp_links: List[Dict] = []
        self.progress_manager: CrawlerProgress = None
        self.browser_pool: BrowserPool = None
    
    def run(self) -> List[Dict]:
        """
        æ‰§è¡Œå®Œæ•´çš„çˆ¬å–æµç¨‹
        """
        self.start_time = time.time()
        self.results = []
        
        try:
            # Phase 1: è·å–é¡¹ç›®åˆ—è¡¨
            self._fetch_program_list()
            
            if not self.temp_links:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•é¡¹ç›®é“¾æ¥")
                return []
            
            # åˆå§‹åŒ–æµè§ˆå™¨æ± (Phase 2 ä½¿ç”¨)
            self.browser_pool = BrowserPool(size=self.max_workers, headless=True)
            self.browser_pool.initialize()
            
            # Phase 2: å¹¶å‘æŠ“å–è¯¦æƒ…
            self._fetch_program_details()
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†çˆ¬å–")
        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            if self.browser_pool:
                self.browser_pool.close_all()
            self.close()
        
        self.print_summary()
        return self.results
    
    def _fetch_program_list(self) -> None:
        """
        Phase 1: ä»åˆ—è¡¨é¡µè·å–æ‰€æœ‰é¡¹ç›®çš„åç§°å’Œé“¾æ¥
        URL å‚æ•° pageSize=10000 ç¡®ä¿ä¸€é¡µæ˜¾ç¤ºæ‰€æœ‰è¯¾ç¨‹
        """
        print_phase_start(
            "Phase 1", 
            "æ­£åœ¨æ‰«æé¡¹ç›®åˆ—è¡¨...",
            total=None
        )
        print(f"   ğŸ“ ç›®æ ‡åœ°å€: {self.list_url}")
        
        try:
            self.driver.get(self.list_url)
            time.sleep(5)  # ç­‰å¾…é¡µé¢åˆå§‹æ¸²æŸ“
            
            self._handle_cookie_banner()
            
            # ç­‰å¾…è¯¾ç¨‹å¡ç‰‡åŠ è½½
            try:
                WebDriverWait(self.driver, PAGE_LOAD_WAIT).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, '.course-listing-card__link'))
                )
            except TimeoutException:
                print("   âš ï¸ è¯¾ç¨‹åˆ—è¡¨åŠ è½½è¶…æ—¶,å°è¯•ç»§ç»­...")
            
            # æå–æ‰€æœ‰é¡¹ç›®
            self._extract_programs_from_page()
            
            print_phase_complete("Phase 1", len(self.temp_links))
            
        except Exception as e:
            print(f"âŒ è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {e}")
    
    def _handle_cookie_banner(self) -> None:
        """å¤„ç† Cookie æ¨ªå¹…"""
        try:
            # å°è¯•ç‚¹å‡»æ¥å—æŒ‰é’® - é€šç”¨é€‰æ‹©å™¨
            selectors = [
                 "button#onetrust-accept-btn-handler",
                 "button[class*='cookie-accept']",
                 "button[class*='agree']"
            ]
            
            for selector in selectors:
                try:
                    btn = self.driver.find_element(By.CSS_SELECTOR, selector)
                    btn.click()
                    time.sleep(1)
                    print("   ğŸª å·²ç‚¹å‡» Cookie æ¥å—æŒ‰é’®")
                    return
                except:
                    continue
        except Exception:
            pass
    
    def _extract_programs_from_page(self) -> None:
        """
        ä»å½“å‰é¡µé¢æå–é¡¹ç›®ä¿¡æ¯
        
        Selectors:
        - Link & Href: .course-listing-card__link
        - Title: h3.course-listing-card__title
        """
        course_cards = self.driver.find_elements(By.CSS_SELECTOR, '.course-listing-card__link')
        print(f"   ğŸ“Š å‘ç° {len(course_cards)} ä¸ªè¯¾ç¨‹å¡ç‰‡")
        
        seen_urls = set()
        extracted_count = 0
        
        for card in course_cards:
            try:
                href = card.get_attribute("href")
                if not href:
                    continue
                    
                # å°è¯•è·å–æ ‡é¢˜
                title = ""
                try:
                    title_elem = card.find_element(By.CSS_SELECTOR, 'h3.course-listing-card__title')
                    title = title_elem.text.strip()
                except NoSuchElementException:
                    # å¦‚æœæ²¡æœ‰ h3ï¼Œå°è¯•ç›´æ¥è·å–æ–‡æœ¬
                    title = card.text.strip().split('\n')[0]
                
                if not title:
                    continue
                
                # ç¡®ä¿ URL æ˜¯ç»å¯¹è·¯å¾„
                if not href.startswith('http'):
                    href = f"{self.base_url}{href}"
                
                if href in seen_urls:
                    continue
                seen_urls.add(href)
                
                self.temp_links.append({
                    "name": title,
                    "link": href
                })
                extracted_count += 1
                
            except Exception as e:
                continue
        
        print(f"   âœ… æˆåŠŸæå– {extracted_count} ä¸ªé¡¹ç›®")

    def _fetch_program_details(self) -> None:
        """Phase 2: å¹¶å‘æŠ“å–æ‰€æœ‰é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯"""
        self.progress_manager = CrawlerProgress(max_workers=self.max_workers)
        self.results = self.progress_manager.run_tasks(
            items=self.temp_links,
            task_func=self._process_single_program,
            task_name="æŠ“å–è¿›åº¦",
            phase_name="Phase 2"
        )
    
    def _process_single_program(self, item: Dict) -> tuple:
        """
        å¤„ç†å•ä¸ªé¡¹ç›®çš„è¯¦æƒ…é¡µæŠ“å–
        """
        item_start = time.time()
        
        result = self.create_result_template(item['name'], item['link'])
        
        # é»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„ç»Ÿä¸€ç”³è¯·é“¾æ¥
        result["ç”³è¯·é“¾æ¥"] = self.university_info.get("apply_register_url", "N/A")
        
        with self.browser_pool.get_browser() as driver:
            try:
                driver.get(item['link'])
                
                # ç­‰å¾…å…³é”®å…ƒç´ åŠ è½½
                try:
                    WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, "h1"))
                    )
                except TimeoutException:
                    pass

                # æå–å¼€å§‹æ—¥æœŸ
                result["é¡¹ç›®opendate"] = self._extract_start_date(driver)
                
                # æå–ç”³è¯·é“¾æ¥ (è¦†ç›–é»˜è®¤å€¼, å› ä¸º Brunel æ¯ä¸ªè¯¾ç¨‹æœ‰ç‰¹å®šä»£ç )
                apply_link = self._extract_application_link(driver)
                if apply_link and apply_link != "N/A":
                    # ä½¿ç”¨ç‰¹å®šè¯¾ç¨‹çš„ç”³è¯·å…¥å£
                    result["ç”³è¯·é“¾æ¥"] = apply_link
                
                # Brunel çš„ Deadline é€šå¸¸ä¸æ˜ç¡®æˆ–å› é¡¹ç›®è€Œå¼‚ï¼Œè¿™é‡Œç•™ N/A æˆ–å°è¯•é€šç”¨æå–
                result["é¡¹ç›®deadline"] = "N/A"
                
            except Exception as e:
                # print(f"Error processing {item['name']}: {e}")
                pass
        
        duration = time.time() - item_start
        return result, duration

    def _extract_start_date(self, driver) -> str:
        """
        æå–è¯¾ç¨‹å¼€å§‹æ—¥æœŸ
        é€šå¸¸åœ¨ .key-info æˆ–ç±»ä¼¼åŒºåŸŸ
        """
        try:
            # ç­–ç•¥1: æŸ¥æ‰¾åŒ…å« "Start date" çš„ Label, ç„¶åæ‰¾å…¶åç»­å†…å®¹æˆ–çˆ¶å®¹å™¨å†…å®¹
            # æ ¹æ®æä¾›çš„æˆªå›¾, Start date æ˜¯ä¸€ä¸ª Hx æˆ– div label, ä¸‹é¢æ˜¯æ—¥æœŸ
            
            # æŸ¥æ‰¾æ‰€æœ‰æ–‡æœ¬ä¸º Start date çš„å…ƒç´ 
            labels = driver.find_elements(By.XPATH, "//*[contains(text(), 'Start date')]")
            
            for label in labels:
                # æ£€æŸ¥çˆ¶å…ƒç´ çš„å†…å®¹
                try:
                    parent = label.find_element(By.XPATH, "./..")
                    text = parent.text.strip()
                    
                    # ç§»é™¤ label æœ¬èº«
                    clean_text = text.replace("Start date", "").strip()
                    if len(clean_text) > 2 and any(m in clean_text for m in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']):
                        return clean_text.replace('\n', ' ').strip()
                except:
                    continue
            
            return "N/A"
        except Exception:
            return "N/A"

    def _extract_application_link(self, driver) -> str:
        """
        ä» 'Apply now' æ‰‹é£ç´ (Accordion) ä¸­æå–ç¬¬ä¸€ä¸ªç”³è¯·é“¾æ¥
        æ³¨æ„: éœ€è¦ç‚¹å‡»æ‰èƒ½å±•å¼€
        """
        try:
            # 1. æ‰¾åˆ° Apply now æŒ‰é’®/æ ‡é¢˜
            # å¸¸è§çš„ç±»å: .accordion__title æˆ–åŒ…å« Apply now æ–‡æœ¬çš„æŒ‰é’®
            apply_btns = driver.find_elements(By.XPATH, "//button[contains(., 'Apply now')] | //a[contains(., 'Apply now')] | //div[contains(@class, 'accordion__title')][contains(., 'Apply now')]")
            
            target_btn = None
            for btn in apply_btns:
                if btn.is_displayed():
                    target_btn = btn
                    break
            
            if not target_btn:
                return "N/A"
            
            # 2. ç‚¹å‡»å±•å¼€ (å¦‚æœæœªå±•å¼€)
            # æ£€æŸ¥ aria-expanded å±æ€§æˆ–ç›´æ¥å°è¯•ç‚¹å‡»
            try:
                # æ»šåŠ¨åˆ°å…ƒç´ ä½ç½®
                driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", target_btn)
                time.sleep(1)
                
                # å°è¯•ç‚¹å‡»
                try:
                    target_btn.click()
                except ElementClickInterceptedException:
                    driver.execute_script("arguments[0].click();", target_btn)
                
                time.sleep(1) # ç­‰å¾…åŠ¨ç”»å±•å¼€
            except Exception:
                pass
            
            # 3. æŸ¥æ‰¾å±•å¼€å†…å®¹ä¸­çš„é“¾æ¥
            # é€šå¸¸åœ¨æŒ‰é’®çš„å…„å¼ŸèŠ‚ç‚¹æˆ–çˆ¶èŠ‚ç‚¹çš„å®¹å™¨é‡Œ
            # å…ˆæ‰¾æœ€è¿‘çš„ accordion content
            try:
                # å°è¯•æ‰¾ç´§é‚»çš„ accordion content
                content = target_btn.find_element(By.XPATH, "./following-sibling::*[contains(@class, 'accordion__content') or contains(@class, 'content')]")
                links = content.find_elements(By.TAG_NAME, 'a')
            except NoSuchElementException:
                # å¯èƒ½ç»“æ„ä¸åŒ, å°è¯•åœ¨æ•´ä¸ª document ä¸­æ‰¾ Apply now ä¸‹æ–¹çš„é“¾æ¥
                # æˆ–è€…çˆ¶çº§å®¹å™¨ä¸‹çš„é“¾æ¥
                container = target_btn.find_element(By.XPATH, "./..")
                links = container.find_elements(By.TAG_NAME, 'a')
                # è¿‡æ»¤æ‰ Apply now æŒ‰é’®æœ¬èº«(å¦‚æœæ˜¯aæ ‡ç­¾)
                links = [l for l in links if "Apply now" not in l.text]
            
            # 4. æå–ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„ç”³è¯·é“¾æ¥
            for link in links:
                href = link.get_attribute('href')
                if href and ("evision" in href or "apply" in href):
                    return href
            
            return "N/A"
            
        except Exception:
            return "N/A"


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    with BrunelSpider(headless=False) as spider:
        results = spider.run()
        print(f"\næŠ“å–å®Œæˆ,å…± {len(results)} ä¸ªé¡¹ç›®")
        if results:
            import json
            print("\nå‰3ä¸ªé¡¹ç›®ç¤ºä¾‹:")
            print(json.dumps(results[:3], indent=2, ensure_ascii=False))
