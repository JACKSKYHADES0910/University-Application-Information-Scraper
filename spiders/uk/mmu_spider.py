# -*- coding: utf-8 -*-
"""
æ›¼å½»æ–¯ç‰¹åŸå¸‚å¤§å­¦ (Manchester Metropolitan University) çˆ¬è™«æ¨¡å—
è´Ÿè´£æŠ“å– MMU Postgraduate Taught é¡¹ç›®ä¿¡æ¯
"""

import time
from typing import List, Dict
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from spiders.base_spider import BaseSpider
from utils.progress import CrawlerProgress, print_phase_start, print_phase_complete
from utils.selenium_utils import BrowserPool
from config import MAX_WORKERS, PAGE_LOAD_WAIT


class MMUSpider(BaseSpider):
    """
    æ›¼å½»æ–¯ç‰¹åŸå¸‚å¤§å­¦çˆ¬è™«
    
    è´Ÿè´£ä» Manchester Metropolitan University å®˜ç½‘çˆ¬å–æ‰€æœ‰ Postgraduate Taught é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯,åŒ…æ‹¬:
    - é¡¹ç›®åç§°
    - é¡¹ç›®é“¾æ¥
    - è¯¾ç¨‹å¼€å§‹æ—¥æœŸ
    - ç»Ÿä¸€çš„ç”³è¯·æ³¨å†Œå’Œç™»å½•é“¾æ¥
    
    ç½‘ç«™ç‰¹ç‚¹:
    - ä½¿ç”¨ A-Z å­—æ¯å¯¼èˆªåˆ†ç±»å±•ç¤ºè¯¾ç¨‹
    - åªæœ‰åŒ…å«è¯¾ç¨‹çš„å­—æ¯æŒ‰é’®å¯ç‚¹å‡»
    
    ä½¿ç”¨ç¤ºä¾‹:
        >>> with MMUSpider() as spider:
        ...     data = spider.run()
        ...     print(f"çˆ¬å–äº† {len(data)} æ¡æ•°æ®")
    """
    
    def __init__(self, headless: bool = True, max_workers: int = None):
        """
        åˆå§‹åŒ– MMU çˆ¬è™«
        
        å‚æ•°:
            headless (bool): æ˜¯å¦æ— å¤´æ¨¡å¼è¿è¡Œ
            max_workers (int): å¹¶å‘çº¿ç¨‹æ•°,å¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨ config.py ä¸­çš„é…ç½®
        """
        super().__init__("mmu", headless)
        from config import MAX_WORKERS as CONFIG_MAX_WORKERS
        self.max_workers = max_workers if max_workers is not None else CONFIG_MAX_WORKERS
        self.temp_links: List[Dict] = []  # ä¸´æ—¶å­˜å‚¨é¡¹ç›®é“¾æ¥åˆ—è¡¨
        self.progress_manager: CrawlerProgress = None  # è¿›åº¦ç®¡ç†å™¨
        self.browser_pool: BrowserPool = None  # æµè§ˆå™¨æ± 
    
    def run(self) -> List[Dict]:
        """
        æ‰§è¡Œå®Œæ•´çš„çˆ¬å–æµç¨‹
        
        æµç¨‹:
            1. Phase 1: è·å–æ‰€æœ‰é¡¹ç›®çš„åˆ—è¡¨(åç§°+é“¾æ¥) - é€šè¿‡ A-Z å¯¼èˆª
            2. Phase 2: å¹¶å‘æŠ“å–æ¯ä¸ªé¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯
        
        è¿”å›:
            List[Dict]: æ‰€æœ‰é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯åˆ—è¡¨
        """
        self.start_time = time.time()
        self.results = []
        
        try:
            # Phase 1: è·å–é¡¹ç›®åˆ—è¡¨(é€šè¿‡ A-Z å¯¼èˆª)
            self._fetch_program_list()
            
            if not self.temp_links:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•é¡¹ç›®é“¾æ¥")
                return []
            
            # åˆå§‹åŒ–æµè§ˆå™¨æ± (Phase 2 ä½¿ç”¨)
            self.browser_pool = BrowserPool(size=self.max_workers, headless=True)
            self.browser_pool.initialize()
            
            # Phase 2: å¹¶å‘æŠ“å–è¯¦æƒ…
            self._fetch_program_details()
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†çˆ¬å–")
        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            # å…³é—­æµè§ˆå™¨æ± 
            if self.browser_pool:
                self.browser_pool.close_all()
            self.close()
        
        self.print_summary()
        return self.results
    
    def _fetch_program_list(self) -> None:
        """
        Phase 1: ä» A-Z åˆ—è¡¨é¡µè·å–æ‰€æœ‰é¡¹ç›®çš„åç§°å’Œé“¾æ¥
        
        è¯¥æ–¹æ³•éå†æ‰€æœ‰å¯ç‚¹å‡»çš„å­—æ¯,æå–æ¯ä¸ªå­—æ¯ä¸‹çš„è¯¾ç¨‹åˆ—è¡¨
        MMU ç½‘ç«™ä½¿ç”¨ A-Z å¯¼èˆª,æ¯ä¸ªå­—æ¯å¯¹åº”ä¸€ä¸ªå•ç‹¬çš„é¡µé¢
        """
        print_phase_start(
            "Phase 1", 
            "æ­£åœ¨æ‰«æé¡¹ç›®åˆ—è¡¨ (A-Z å¯¼èˆª)...",
            total=None
        )
        print(f"   ğŸ“ ç›®æ ‡åœ°å€: {self.list_url}")
        
        try:
            # è®¿é—®èµ·å§‹é¡µé¢
            self.driver.get(self.list_url)
            time.sleep(3)  # ç­‰å¾…é¡µé¢åŠ è½½
            
            # è·å–æ‰€æœ‰å¯ç‚¹å‡»çš„å­—æ¯æŒ‰é’®
            active_letters = self._get_active_letters()
            
            if not active_letters:
                print("   âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æ´»è·ƒå­—æ¯")
                return
            
            print(f"   ğŸ“Š å‘ç° {len(active_letters)} ä¸ªæ´»è·ƒå­—æ¯: {', '.join(active_letters)}")
            
            # éå†æ¯ä¸ªå­—æ¯
            for idx, letter in enumerate(active_letters, 1):
                print(f"\n   ğŸ”¤ æ­£åœ¨å¤„ç†å­—æ¯ [{letter}] ({idx}/{len(active_letters)})...")
                self._process_letter(letter)
                time.sleep(1)  # ç¤¼è²Œå»¶è¿Ÿ
            
            print_phase_complete("Phase 1", len(self.temp_links))
            
        except Exception as e:
            print(f"âŒ è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {e}")
    
    def _get_active_letters(self) -> List[str]:
        """
        è·å–æ‰€æœ‰åŒ…å«è¯¾ç¨‹çš„æ´»è·ƒå­—æ¯
        
        è¿”å›:
            List[str]: æ´»è·ƒå­—æ¯åˆ—è¡¨ (ä¾‹å¦‚: ['A', 'B', 'C', ...])
        """
        try:
            # ç­‰å¾… A-Z å¯¼èˆªåŠ è½½
            WebDriverWait(self.driver, PAGE_LOAD_WAIT).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, '.a-to-z-button'))
            )
            
            # æŸ¥æ‰¾æ‰€æœ‰å¯ç‚¹å‡»çš„å­—æ¯æŒ‰é’® (ä½¿ç”¨ <a> æ ‡ç­¾)
            active_buttons = self.driver.find_elements(By.CSS_SELECTOR, 'a.a-to-z-button')
            
            letters = []
            for button in active_buttons:
                # è·å–å­—æ¯æ–‡æœ¬ (ä¾‹å¦‚ "A 14" -> "A")
                text = button.text.strip().split()[0]
                if text and len(text) == 1 and text.isalpha():
                    letters.append(text.upper())
            
            return letters
            
        except Exception as e:
            print(f"   âš ï¸ è·å–æ´»è·ƒå­—æ¯å¤±è´¥: {e}")
            return []
    
    def _process_letter(self, letter: str) -> None:
        """
        å¤„ç†å•ä¸ªå­—æ¯ä¸‹çš„æ‰€æœ‰è¯¾ç¨‹
        
        å‚æ•°:
            letter (str): å­—æ¯ (ä¾‹å¦‚ 'A')
        """
        try:
            # æ„å»ºå­—æ¯é¡µé¢ URL
            letter_url = f"{self.list_url}/{letter.lower()}"
            self.driver.get(letter_url)
            
            # ç­‰å¾…è¯¾ç¨‹åˆ—è¡¨åŠ è½½
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href*="/study/postgraduate/course/"]'))
                )
            except TimeoutException:
                print(f"      âš ï¸ å­—æ¯ [{letter}] é¡µé¢åŠ è½½è¶…æ—¶")
                return
            
            # æå–è¯¾ç¨‹ä¿¡æ¯
            self._extract_programs_from_page(letter)
            
        except Exception as e:
            print(f"      âŒ å¤„ç†å­—æ¯ [{letter}] æ—¶å‡ºé”™: {e}")
    
    def _extract_programs_from_page(self, letter: str) -> None:
        """
        ä»å½“å‰é¡µé¢æå–é¡¹ç›®ä¿¡æ¯
        
        å‚æ•°:
            letter (str): å½“å‰å­—æ¯
        """
        # å»é‡å¤„ç†
        seen_urls = set(link["link"] for link in self.temp_links)
        
        # æŸ¥æ‰¾æ‰€æœ‰è¯¾ç¨‹é“¾æ¥
        course_links = self.driver.find_elements(By.CSS_SELECTOR, 'a[href*="/study/postgraduate/course/"]')
        
        extracted_count = 0
        
        for link in course_links:
            try:
                # è·å–é“¾æ¥ URL
                href = link.get_attribute("href")
                
                if not href or href in seen_urls:
                    continue
                
                # è·å–è¯¾ç¨‹åç§° - ä» h4 å…ƒç´ æå–
                try:
                    title_elem = link.find_element(By.CSS_SELECTOR, 'h4')
                    course_title = title_elem.text.strip()
                except NoSuchElementException:
                    # å¦‚æœæ‰¾ä¸åˆ° h4ï¼Œè·³è¿‡
                    continue
                
                # å°è¯•è·å–å­¦ä½ç±»å‹ (MA, MSc, etc.)
                try:
                    award_elem = link.find_element(By.XPATH, "./div[1]")
                    award_text = award_elem.text.strip()
                    # å¦‚æœå­¦ä½ç±»å‹å­˜åœ¨ä¸”åˆç†ï¼Œå°†å…¶æ”¾åœ¨æ‹¬å·ä¸­
                    if award_text and len(award_text) <= 10:
                        name = f"{course_title} ({award_text})"
                    else:
                        name = course_title
                except:
                    name = course_title
                
                if not name or len(name) < 3:
                    continue
                
                # ç¡®ä¿ URL æ ¼å¼æ­£ç¡®
                if not href.startswith('http'):
                    href = f"{self.base_url}{href}"
                
                self.temp_links.append({
                    "name": name,
                    "link": href
                })
                extracted_count += 1
                    
            except Exception:
                continue
        
        print(f"      âœ… å­—æ¯ [{letter}]: æå– {extracted_count} ä¸ªè¯¾ç¨‹")
    
    def _fetch_program_details(self) -> None:
        """
        Phase 2: å¹¶å‘æŠ“å–æ‰€æœ‰é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯
        
        ä½¿ç”¨è¿›åº¦ç®¡ç†å™¨å’Œæµè§ˆå™¨æ± æ‰§è¡Œå¹¶å‘ä»»åŠ¡
        """
        # åˆ›å»ºè¿›åº¦ç®¡ç†å™¨
        self.progress_manager = CrawlerProgress(max_workers=self.max_workers)
        
        # æ‰§è¡Œå¹¶å‘æŠ“å–
        self.results = self.progress_manager.run_tasks(
            items=self.temp_links,
            task_func=self._process_single_program,
            task_name="æŠ“å–è¿›åº¦",
            phase_name="Phase 2"
        )
    
    def _process_single_program(self, item: Dict) -> tuple:
        """
        å¤„ç†å•ä¸ªé¡¹ç›®çš„è¯¦æƒ…é¡µæŠ“å–
        
        ä½¿ç”¨æµè§ˆå™¨æ± å¤ç”¨æµè§ˆå™¨å®ä¾‹,æå‡æ€§èƒ½
        
        å‚æ•°:
            item (Dict): åŒ…å« name å’Œ link çš„é¡¹ç›®ä¿¡æ¯
        
        è¿”å›:
            tuple: (ç»“æœå­—å…¸, è€—æ—¶ç§’æ•°)
        """
        item_start = time.time()
        
        # åˆ›å»ºç»“æœæ¨¡æ¿
        result = self.create_result_template(item['name'], item['link'])
        
        # è®¾ç½®ç»Ÿä¸€çš„ç”³è¯·é“¾æ¥(ä»é…ç½®è¯»å–)
        result["ç”³è¯·é“¾æ¥"] = self.university_info.get("apply_register_url", "N/A")
        
        # ä»æµè§ˆå™¨æ± è·å–å®ä¾‹
        with self.browser_pool.get_browser() as driver:
            try:
                # è®¿é—®é¡¹ç›®è¯¦æƒ…é¡µ
                driver.get(item['link'])
                
                # ç­‰å¾…é¡µé¢åŠ è½½
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "h1"))
                )
                
                # æŠ“å–å¼€å§‹æ—¥æœŸ
                result["é¡¹ç›®opendate"] = self._extract_start_date(driver)
                
                # å°è¯•æŠ“å– deadline ä¿¡æ¯
                result["é¡¹ç›®deadline"] = self._extract_deadline(driver)
                
            except TimeoutException:
                # è¯¦æƒ…é¡µåŠ è½½è¶…æ—¶,ä¿æŒ N/A
                pass
            except Exception:
                # å…¶ä»–é”™è¯¯,ä¿æŒ N/A
                pass
        
        duration = time.time() - item_start
        return result, duration
    
    def _extract_start_date(self, driver) -> str:
        """
        æå–è¯¾ç¨‹å¼€å§‹æ—¥æœŸ
        
        MMU çš„è¯¾ç¨‹å¼€å§‹æ—¥æœŸé€šå¸¸åœ¨ "Fact file" åŒºåŸŸ
        """
        try:
            # æ–¹æ³•1: æŸ¥æ‰¾åŒ…å« "Start date" çš„å…ƒç´ 
            start_elements = driver.find_elements(
                By.XPATH, 
                "//*[contains(text(), 'Start date')]"
            )
            
            months = ['January', 'February', 'March', 'April', 'May', 'June', 
                     'July', 'August', 'September', 'October', 'November', 'December',
                     'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 
                     'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
            
            for elem in start_elements:
                try:
                    # æŸ¥æ‰¾çˆ¶å…ƒç´ æˆ–ç›¸é‚»å…ƒç´ 
                    parent = elem.find_element(By.XPATH, "./..")
                    text = parent.text.strip()
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æœˆä»½ä¿¡æ¯
                    if any(month in text for month in months):
                        # æå–æ—¥æœŸéƒ¨åˆ† (ç§»é™¤ "Start date" æ ‡ç­¾)
                        lines = text.split('\n')
                        for line in lines:
                            if any(month in line for month in months):
                                return line.strip()
                except:
                    continue
            
            # æ–¹æ³•2: ç›´æ¥æŸ¥æ‰¾åŒ…å«æœˆä»½çš„æ–‡æœ¬
            for month in months:
                try:
                    month_elements = driver.find_elements(
                        By.XPATH,
                        f"//*[contains(text(), '{month}')]"
                    )
                    for elem in month_elements:
                        text = elem.text.strip()
                        # ç¡®ä¿æ–‡æœ¬ä¸æ˜¯å¤ªé•¿(é¿å…è¯¯åŒ¹é…æ®µè½)
                        if text and len(text) < 50 and any(m in text for m in months):
                            return text
                except:
                    continue
            
            return "N/A"
            
        except Exception:
            return "N/A"
    
    def _extract_deadline(self, driver) -> str:
        """
        æå–ç”³è¯·æˆªæ­¢æ—¥æœŸ
        
        MMU é‡‡ç”¨æ»šåŠ¨æ‹›ç”Ÿåˆ¶åº¦,æ‰€æœ‰è¯¾ç¨‹ç»Ÿä¸€è¿”å› N/A
        """
        return "N/A"


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    with MMUSpider(headless=False) as spider:
        results = spider.run()
        
        print(f"\næŠ“å–å®Œæˆ,å…± {len(results)} ä¸ªé¡¹ç›®")
        if results:
            import json
            print("\nå‰3ä¸ªé¡¹ç›®ç¤ºä¾‹:")
            print(json.dumps(results[:3], indent=2, ensure_ascii=False))
