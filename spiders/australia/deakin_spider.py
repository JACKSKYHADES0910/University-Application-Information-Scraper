# -*- coding: utf-8 -*-
"""
è¿ªè‚¯å¤§å­¦ (Deakin University) çˆ¬è™«æ¨¡å—
è´Ÿè´£æŠ“å– Deakin Postgraduate é¡¹ç›®ä¿¡æ¯
"""

import time
import re
from typing import List, Dict
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException

from spiders.base_spider import BaseSpider
from utils.progress import CrawlerProgress, print_phase_start, print_phase_complete
from utils.selenium_utils import BrowserPool
from config import MAX_WORKERS, PAGE_LOAD_WAIT


class DeakinSpider(BaseSpider):
    """
    è¿ªè‚¯å¤§å­¦çˆ¬è™«
    
    è´Ÿè´£ä» Deakin University å®˜ç½‘çˆ¬å–æ‰€æœ‰ Postgraduate é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯,åŒ…æ‹¬:
    - é¡¹ç›®åç§°
    - é¡¹ç›®é“¾æ¥
    - å­¦ä¹ é¢†åŸŸ(Study area)
    - Key dates(æˆªæ­¢æ—¥æœŸ)
    - ç»Ÿä¸€çš„ç”³è¯·æ³¨å†Œå’Œç™»å½•é“¾æ¥
    
    ç‰¹ç‚¹:
    - ä½¿ç”¨"Study area"ç­›é€‰å™¨éå†æ‰€æœ‰å­¦ç§‘é¢†åŸŸ
    - ç›´æ¥è®°å½•Study areaä½œä¸º"å­¦ä¹ é¢†åŸŸ"
    - æ”¯æŒåˆ†é¡µ(æ¯é¡µ12ä¸ªé¡¹ç›®)
    
    ä½¿ç”¨ç¤ºä¾‹:
        >>> with DeakinSpider() as spider:
        ...     data = spider.run()
        ...     print(f"çˆ¬å–äº† {len(data)} æ¡æ•°æ®")
    """
    
    def __init__(self, headless: bool = True, max_workers: int = None):
        """
        åˆå§‹åŒ– Deakin çˆ¬è™«
        
        å‚æ•°:
            headless (bool): æ˜¯å¦æ— å¤´æ¨¡å¼è¿è¡Œ
            max_workers (int): å¹¶å‘çº¿ç¨‹æ•°,å¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨ config.py ä¸­çš„é…ç½®
        """
        super().__init__("deakin", headless)
        from config import MAX_WORKERS as CONFIG_MAX_WORKERS
        self.max_workers = max_workers if max_workers is not None else CONFIG_MAX_WORKERS
        self.temp_links: List[Dict] = []  # ä¸´æ—¶å­˜å‚¨é¡¹ç›®é“¾æ¥åˆ—è¡¨(å¸¦å­¦ä¹ é¢†åŸŸä¿¡æ¯)
        self.progress_manager: CrawlerProgress = None  # è¿›åº¦ç®¡ç†å™¨
        self.browser_pool: BrowserPool = None  # æµè§ˆå™¨æ± 
        
        # Study areaåˆ—è¡¨ï¼ˆå­¦ä¹ é¢†åŸŸï¼‰
        self.study_areas = [
            "Arts, humanities and social sciences",
            "Education and teaching",
            "Media and communications",
            "Film, television and animation",
            "Design and creative arts",
            "Accounting and finance",
            "Business and economics",
            "Law",
            "Management and MBA",
            "Medicine",
            "Nursing and midwifery",
            "Psychology and mental health",
            "Health and community services",
            "Food, nutrition and dietetics",
            "Architecture",
            "Construction and property",
            "Data science and analytics",
            "Engineering",
            "Environment and sustainability",
            "Information technology and cyber security",
            "Science",
            "Sport"
        ]
    
    def run(self) -> List[Dict]:
        """
        æ‰§è¡Œå®Œæ•´çš„çˆ¬å–æµç¨‹
        
        æµç¨‹:
            1. Phase 1: éå†æ‰€æœ‰Study area,è·å–æ¯ä¸ªåˆ†ç±»ä¸‹çš„é¡¹ç›®åˆ—è¡¨
            2. Phase 2: å¹¶å‘æŠ“å–æ¯ä¸ªé¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯
        
        è¿”å›:
            List[Dict]: æ‰€æœ‰é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯åˆ—è¡¨
        """
        self.start_time = time.time()
        self.results = []
        
        try:
            # Phase 1: éå†æ‰€æœ‰Study areaè·å–é¡¹ç›®åˆ—è¡¨
            self._fetch_program_list()
            
            if not self.temp_links:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•é¡¹ç›®é“¾æ¥", flush=True)
                return []
            
            # åˆå§‹åŒ–æµè§ˆå™¨æ± (Phase 2 ä½¿ç”¨)
            self.browser_pool = BrowserPool(size=self.max_workers, headless=True)
            self.browser_pool.initialize()
            
            # Phase 2: å¹¶å‘æŠ“å–è¯¦æƒ…
            self._fetch_program_details()
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†çˆ¬å–", flush=True)
        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", flush=True)
        finally:
            # å…³é—­æµè§ˆå™¨æ± 
            if self.browser_pool:
                self.browser_pool.close_all()
            self.close()
        
        self.print_summary()
        return self.results
    
    def _fetch_program_list(self) -> None:
        """
        Phase 1: ç›´æ¥éå†å…¨é‡åˆ—è¡¨çš„æ‰€æœ‰åˆ†é¡µï¼Œè·å–å…¨éƒ¨é¡¹ç›®
        
        è¯¥æ–¹æ³•ä¼š:
        1. è®¿é—®è¯¾ç¨‹åˆ—è¡¨é¡µ
        2. éå†æ‰€æœ‰åˆ†é¡µæå–é¡¹ç›®
        3. å­¦ä¹ é¢†åŸŸå­—æ®µè®¾ä¸º"N/A"(å› ä¸ç­›é€‰æ— æ³•ç¡®å®š)
        """
        print_phase_start(
            "Phase 1",
            f"æ­£åœ¨æ‰«æå…¨é‡é¡¹ç›®åˆ—è¡¨(175ä¸ªé¡¹ç›®)...",
            total=None
        )
        print(f"   ğŸ“ ç›®æ ‡åœ°å€: {self.list_url}", flush=True)
        
        try:
            # è®¿é—®èµ·å§‹é¡µé¢
            self.driver.get(self.list_url)
            time.sleep(3)  # ç­‰å¾…é¡µé¢åŠ è½½
            
            # å¤„ç†CookieåŒæ„å¯¹è¯æ¡†
            self._handle_cookie_consent()
            
            # éå†æ‰€æœ‰åˆ†é¡µæå–é¡¹ç›®
            page_num = 1
            total_extracted = 0
            
            while True:
                print(f"\n   ğŸ“„ æ­£åœ¨å¤„ç†ç¬¬ {page_num} é¡µ...", flush=True)
                
                # æå–å½“å‰é¡µé¢çš„é¡¹ç›®
                count = self._extract_programs_from_current_page()
                total_extracted += count
                
                print(f"      âœ… ç¬¬ {page_num} é¡µ: æå– {count} ä¸ªé¡¹ç›® (ç´¯è®¡: {total_extracted})", flush=True)
                
                if count == 0:
                    print(f"      âš ï¸ å½“å‰é¡µæ— é¡¹ç›®ï¼Œåœæ­¢ç¿»é¡µ", flush=True)
                    break
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
                if not self._has_next_page():
                    print(f"   âœ… å·²åˆ°è¾¾æœ€åä¸€é¡µ", flush=True)
                    break
                
                # ç‚¹å‡»ä¸‹ä¸€é¡µ
                if not self._click_next_page():
                    print(f"   âš ï¸ æ— æ³•ç‚¹å‡»ä¸‹ä¸€é¡µï¼Œåœæ­¢ç¿»é¡µ", flush=True)
                    break
                
                page_num += 1
                time.sleep(2)  # ç­‰å¾…ä¸‹ä¸€é¡µåŠ è½½
            
            # è¿›è¡Œåˆ†ç±»
            self._classify_programs()
            
            print_phase_complete("Phase 1", len(self.temp_links))
            
        except Exception as e:
            print(f"âŒ è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {e}", flush=True)
    
    def _handle_cookie_consent(self) -> None:
        """å¤„ç†CookieåŒæ„å¯¹è¯æ¡†"""
        try:
            # ç­‰å¾…å¹¶å°è¯•ç‚¹å‡»"OK"æˆ–"Accept"æŒ‰é’®
            accept_selectors = [
                "button.cc-dismiss",
                "button[aria-label*='accept']",
                "button[aria-label*='Accept']",
                "button#onetrust-accept-btn-handler",
                "a.cc-btn"
            ]
            
            for selector in accept_selectors:
                try:
                    accept_button = WebDriverWait(self.driver, 5).until(
                        EC.element_to_be_clickable((By.CSS_SELECTOR, selector))
                    )
                    accept_button.click()
                    print("   âœ… å·²æ¥å— Cookie", flush=True)
                    time.sleep(1)
                    return
                except:
                    continue
            
            print("   â„¹ï¸ æœªæ‰¾åˆ° Cookie å¯¹è¯æ¡†", flush=True)
            
        except Exception:
            pass
    
    def _apply_study_area_filter(self, study_area: str) -> None:
        """
        åº”ç”¨Study areaç­›é€‰å™¨
        
        å‚æ•°:
            study_area (str): è¦ç­›é€‰çš„Study areaåç§°
        """
        try:
            # é¦–å…ˆå°è¯•å…³é—­ä»»ä½•å·²æ‰“å¼€çš„ç­›é€‰å™¨é¢æ¿
            try:
                # æŸ¥æ‰¾å¯èƒ½æ‰“å¼€çš„ç­›é€‰å™¨é¢æ¿å¹¶å…³é—­
                # ç‚¹å‡»"Study area"æŒ‰é’®å¦‚æœå®ƒå·²ç»å±•å¼€åˆ™ä¼šå…³é—­
                # æˆ–è€…æŸ¥æ‰¾å…³é—­æŒ‰é’®/backdropç‚¹å‡»
                backdrop = self.driver.find_elements(By.CSS_SELECTOR, ".backdrop, [class*='backdrop']")
                if backdrop:
                    backdrop[0].click()
                    time.sleep(0.5)
            except:
                pass
            
            # ç‚¹å‡»"Study area"æŒ‰é’®æ‰“å¼€ç­›é€‰å™¨
            study_area_button = WebDriverWait(self.driver, 10).until(
                EC.element_to_be_clickable((By.XPATH, "//button[contains(., 'Study area')]"))
            )
            
            # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", study_area_button)
            time.sleep(0.5)
            
            # ä½¿ç”¨JavaScriptç‚¹å‡»ç¡®ä¿æˆåŠŸ
            self.driver.execute_script("arguments[0].click();", study_area_button)
            time.sleep(1.5)  # å¢åŠ ç­‰å¾…æ—¶é—´
            
            # ç­‰å¾…å¤é€‰æ¡†å‡ºç°
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "input[type='checkbox']"))
            )
            
            # æ‰¾åˆ°å¯¹åº”çš„å¤é€‰æ¡†å¹¶ç‚¹å‡»
            # å¤é€‰æ¡†é€šå¸¸åœ¨labelä¸­,labelæ–‡æœ¬åŒ…å«study areaåç§°
            checkbox_label = self.driver.find_element(
                By.XPATH,
                f"//label[contains(text(), '{study_area}')]"
            )
            
            # æ»šåŠ¨åˆ°å¤é€‰æ¡†ä½ç½®
            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", checkbox_label)
            time.sleep(0.5)
            
            # ä½¿ç”¨JavaScriptç‚¹å‡»å¤é€‰æ¡†label
            self.driver.execute_script("arguments[0].click();", checkbox_label)
            time.sleep(0.5)
            
            # ç‚¹å‡»"APPLY"æŒ‰é’®åº”ç”¨ç­›é€‰
            apply_button = self.driver.find_element(
                By.XPATH,
                "//button[contains(text(), 'APPLY') or contains(text(), 'Apply')]"
            )
            
            # ä½¿ç”¨JavaScriptç‚¹å‡»ç¡®ä¿æˆåŠŸ
            self.driver.execute_script("arguments[0].click();", apply_button)
            time.sleep(2)  # ç­‰å¾…ç­›é€‰ç»“æœåŠ è½½
            
            print(f"      âœ… å·²åº”ç”¨ç­›é€‰: {study_area}", flush=True)
            
        except Exception as e:
            print(f"      âš ï¸ åº”ç”¨ç­›é€‰å¤±è´¥: {e}", flush=True)
            raise
    
    def _extract_all_programs_in_area(self, study_area: str) -> None:
        """
        æå–å½“å‰Study areaä¸‹çš„æ‰€æœ‰é¡¹ç›®(å¤„ç†åˆ†é¡µ)
        
        å‚æ•°:
            study_area (str): å½“å‰Study areaåç§°
        """
        page_num = 1
        total_extracted = 0
        
        while True:
            # æå–å½“å‰é¡µé¢çš„é¡¹ç›®
            count = self._extract_programs_from_page(study_area)
            total_extracted += count
            
            print(f"      ğŸ“„ ç¬¬ {page_num} é¡µ: æå– {count} ä¸ªé¡¹ç›® (ç´¯è®¡: {total_extracted})", flush=True)
            
            if count == 0:
                break
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
            if not self._has_next_page():
                print(f"      âœ… [{study_area}] å·²åˆ°è¾¾æœ€åä¸€é¡µ", flush=True)
                break
            
            # ç‚¹å‡»ä¸‹ä¸€é¡µ
            if not self._click_next_page():
                print(f"      âš ï¸ æ— æ³•ç‚¹å‡»ä¸‹ä¸€é¡µ,åœæ­¢ç¿»é¡µ", flush=True)
                break
            
            page_num += 1
            time.sleep(2)  # ç­‰å¾…ä¸‹ä¸€é¡µåŠ è½½
        
        print(f"      âœ… [{study_area}] å…±æå– {total_extracted} ä¸ªé¡¹ç›®", flush=True)
        
        # é‡ç½®ç­›é€‰å™¨,å‡†å¤‡ä¸‹ä¸€ä¸ªStudy area
        self._reset_filters()
    
    def _extract_programs_from_current_page(self) -> int:
        """
        ä»å½“å‰é¡µé¢æå–é¡¹ç›®ä¿¡æ¯ï¼ˆä¸ä½¿ç”¨Study areaç­›é€‰ï¼‰
        
        è¿”å›:
            int: æå–çš„é¡¹ç›®æ•°é‡
        """
        extracted_count = 0
        
        try:
            # ç­‰å¾…è¯¾ç¨‹å¡ç‰‡åŠ è½½
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "article, .course-card, a[href*='/course/']"))
            )
            
            # æŸ¥æ‰¾æ‰€æœ‰è¯¾ç¨‹é“¾æ¥
            course_links = self.driver.find_elements(
                By.CSS_SELECTOR,
                "a[href*='/course/']"
            )
            
            for link in course_links:
                try:
                    href = link.get_attribute("href")
                    
                    # è¿‡æ»¤æ‰éè¯¦æƒ…é¡µé“¾æ¥
                    if not href or '/find-a-course/' in href:
                        continue
                    
                    # ç¡®ä¿æ˜¯å®Œæ•´çš„è¯¾ç¨‹è¯¦æƒ…é¡µé“¾æ¥
                    if not re.match(r'https://www\.deakin\.edu\.au/course/[^/]+$', href):
                        continue
                    
                    # è·å–è¯¾ç¨‹åç§°
                    course_title = link.text.strip()
                    if not course_title or len(course_title) < 3:
                        course_title = link.get_attribute("title") or ""
                    
                    if not course_title or len(course_title) < 3:
                        continue
                    
                    # æ¸…ç†è¯¾ç¨‹åç§°
                    course_title = re.sub(r'\s+', ' ', course_title).strip()
                    
                    # æ·»åŠ åˆ°åˆ—è¡¨ï¼ˆä¸ç­›é€‰ï¼Œå­¦ä¹ é¢†åŸŸè®¾ä¸ºN/Aï¼‰
                    self.temp_links.append({
                        "name": course_title,
                        "link": href,
                        "study_area": "N/A"  # ä¸ç­›é€‰æ—¶æ— æ³•ç¡®å®šå­¦ä¹ é¢†åŸŸ
                    })
                    extracted_count += 1
                    
                except Exception:
                    continue
            
        except TimeoutException:
            print(f"      âš ï¸ é¡µé¢åŠ è½½è¶…æ—¶", flush=True)
        except Exception as e:
            print(f"      âš ï¸ æå–é¡¹ç›®å¤±è´¥: {e}", flush=True)
        
        return extracted_count
    
    def _extract_programs_from_page(self, study_area: str) -> int:
        """
        ä»å½“å‰é¡µé¢æå–é¡¹ç›®ä¿¡æ¯
        
        å‚æ•°:
            study_area (str): å½“å‰Study area(å°†ä½œä¸º"å­¦é™¢"å­—æ®µ)
        
        è¿”å›:
            int: æå–çš„é¡¹ç›®æ•°é‡
        """
        extracted_count = 0
        # ç§»é™¤å»é‡é€»è¾‘ï¼Œå…è®¸åŒä¸€é¡¹ç›®å‡ºç°åœ¨å¤šä¸ªStudy areaä¸‹
        
        try:
            # ç­‰å¾…è¯¾ç¨‹å¡ç‰‡åŠ è½½
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "article, .course-card, a[href*='/course/']"))
            )
            
            # æŸ¥æ‰¾æ‰€æœ‰è¯¾ç¨‹é“¾æ¥
            # Deakinçš„è¯¾ç¨‹é“¾æ¥æ ¼å¼: /course/xxx
            course_links = self.driver.find_elements(
                By.CSS_SELECTOR,
                "a[href*='/course/']"
            )
            
            for link in course_links:
                try:
                    href = link.get_attribute("href")
                    
                    # è¿‡æ»¤æ‰éè¯¦æƒ…é¡µé“¾æ¥
                    if not href or '/find-a-course/' in href:
                        continue
                    
                    # ç¡®ä¿æ˜¯å®Œæ•´çš„è¯¾ç¨‹è¯¦æƒ…é¡µé“¾æ¥
                    if not re.match(r'https://www\.deakin\.edu\.au/course/[^/]+$', href):
                        continue
                    
                    # è·å–è¯¾ç¨‹åç§°
                    # å°è¯•ä»æ–‡æœ¬æˆ–titleå±æ€§æå–
                    course_title = link.text.strip()
                    if not course_title or len(course_title) < 3:
                        course_title = link.get_attribute("title") or ""
                    
                    if not course_title or len(course_title) < 3:
                        continue
                    
                    # æ¸…ç†è¯¾ç¨‹åç§°(å»é™¤å¤šä½™çš„æ¢è¡Œå’Œç©ºæ ¼)
                    course_title = re.sub(r'\s+', ' ', course_title).strip()
                    
                    # æ·»åŠ åˆ°åˆ—è¡¨ï¼ˆä¸å»é‡ï¼Œå…è®¸é‡å¤ï¼‰
                    self.temp_links.append({
                        "name": course_title,
                        "link": href,
                        "study_area": study_area  # ç›´æ¥ä½¿ç”¨Study area
                    })
                    extracted_count += 1
                    
                except Exception:
                    continue
            
        except TimeoutException:
            print(f"      âš ï¸ é¡µé¢åŠ è½½è¶…æ—¶", flush=True)
        except Exception as e:
            print(f"      âš ï¸ æå–é¡¹ç›®å¤±è´¥: {e}", flush=True)
        
        return extracted_count
    
    def _has_next_page(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ"""
        try:
            # ç­–ç•¥: æŸ¥æ‰¾ Next æŒ‰é’® (a.next)
            # å¦‚æœå­˜åœ¨ä¸”çˆ¶å…ƒç´  li æ²¡æœ‰ disabled ç±»ï¼Œåˆ™è¡¨ç¤ºæœ‰ä¸‹ä¸€é¡µ
            next_link = self.driver.find_elements(By.CSS_SELECTOR, "a.next")
            
            if not next_link:
                return False
                
            # æ£€æŸ¥çˆ¶å…ƒç´  li æ˜¯å¦ disabled
            try:
                parent_li = next_link[0].find_element(By.XPATH, "./..")
                li_class = parent_li.get_attribute("class") or ""
                if "disabled" in li_class:
                    return False
                return True
            except:
                # æ— æ³•è·å–çˆ¶å…ƒç´ ï¼Œå‡è®¾å¦‚æœæœ‰a.nextå°±èƒ½ç‚¹å‡»
                return True
            
        except Exception:
            return False
    
    def _click_next_page(self) -> bool:
        """ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®"""
        try:
            next_buttons = self.driver.find_elements(By.CSS_SELECTOR, "a.next")
            if not next_buttons:
                return False
            
            next_button = next_buttons[0]
            
            # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", next_button)
            time.sleep(0.5)
            
            # ç‚¹å‡»
            try:
                next_button.click()
            except ElementClickInterceptedException:
                self.driver.execute_script("arguments[0].click();", next_button)
            
            return True
            
        except Exception:
            return False
    
    def _reset_filters(self) -> None:
        """é‡ç½®æ‰€æœ‰ç­›é€‰å™¨,å‡†å¤‡ä¸‹ä¸€ä¸ªStudy area"""
        try:
            # æŸ¥æ‰¾å¹¶ç‚¹å‡»"RESET"æŒ‰é’®
            reset_button = self.driver.find_element(
                By.XPATH,
                "//button[contains(text(), 'RESET') or contains(text(), 'Reset')]"
            )
            
            reset_button.click()
            time.sleep(1.5)
            
            print(f"      ğŸ”„ å·²é‡ç½®ç­›é€‰å™¨", flush=True)
            
        except Exception:
            # å¦‚æœæ²¡æœ‰RESETæŒ‰é’®,åˆ·æ–°é¡µé¢
            print(f"      ğŸ”„ åˆ·æ–°é¡µé¢ä»¥é‡ç½®ç­›é€‰å™¨", flush=True)
            self.driver.get(self.list_url)
            time.sleep(2)

    def _collect_links_from_page(self) -> List[str]:
        """
        æ”¶é›†å½“å‰é¡µé¢çš„æ‰€æœ‰é¡¹ç›®é“¾æ¥
        """
        links = []
        try:
            WebDriverWait(self.driver, 5).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "article, .course-card, a[href*='/course/']"))
            )
            elements = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='/course/']")
            for el in elements:
                try:
                    href = el.get_attribute("href")
                    if href and '/course/' in href and '/find-a-course/' not in href:
                         # ç¡®ä¿æ˜¯å®Œæ•´çš„è¯¾ç¨‹è¯¦æƒ…é¡µé“¾æ¥
                        if re.match(r'https://www\.deakin\.edu\.au/course/[^/]+$', href):
                            links.append(href)
                except:
                    continue
        except:
            pass
        return links

    def _classify_programs(self) -> None:
        """
        Phase 1.5: éå†Study Areaç­›é€‰å™¨ï¼Œå¯¹å·²æŠ“å–çš„é¡¹ç›®è¿›è¡Œåˆ†ç±»
        """
        print_phase_start("Phase 1.5", f"æ­£åœ¨å¯¹ {len(self.temp_links)} ä¸ªé¡¹ç›®è¿›è¡Œåˆ†ç±»...", total=len(self.study_areas))
        
        # å»ºç«‹é“¾æ¥æ˜ å°„è¡¨ {link: item}
        # ä½¿ç”¨ URL ä½œä¸ºé”®ï¼Œæ–¹ä¾¿å¿«é€ŸæŸ¥æ‰¾
        link_map = {item['link']: item for item in self.temp_links}
        
        try:
            # ç¡®ä¿åœ¨åˆ—è¡¨é¡µ
            if "postgraduate-courses" not in self.driver.current_url:
                self.driver.get(self.list_url)
                time.sleep(2)
            
            for idx, area in enumerate(self.study_areas, 1):
                print(f"   ğŸ“š [{idx}/{len(self.study_areas)}] æ­£åœ¨æ‰«æåˆ†ç±»: {area}", flush=True)
                
                try:
                    self._apply_study_area_filter(area)
                    
                    # éå†è¯¥åˆ†ç±»ä¸‹çš„æ‰€æœ‰åˆ†é¡µ
                    while True:
                        # æ”¶é›†å½“å‰é¡µé“¾æ¥
                        links = self._collect_links_from_page()
                        
                        # æ›´æ–°åˆ†ç±»ä¿¡æ¯
                        match_count = 0
                        for link in links:
                            if link in link_map:
                                item = link_map[link]
                                if item['study_area'] == "N/A":
                                    item['study_area'] = area
                                elif area not in item['study_area']:
                                    item['study_area'] += f", {area}"
                                match_count += 1
                        
                        # print(f"      - æœ¬é¡µåŒ¹é…: {match_count}/{len(links)}", flush=True)
                        
                        if not self._has_next_page():
                            break
                            
                        if not self._click_next_page():
                            break
                            
                        time.sleep(1.5)
                        
                except Exception as e:
                    print(f"      âš ï¸ åˆ†ç±»æ‰«æå¤±è´¥: {e}", flush=True)
                
                self._reset_filters()
                time.sleep(1)
                
        except Exception as e:
            print(f"âŒ åˆ†ç±»è¿‡ç¨‹å‡ºé”™: {e}", flush=True)
    
    def _fetch_program_details(self) -> None:
        """Phase 2: å¹¶å‘æŠ“å–æ‰€æœ‰é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯"""
        self.progress_manager = CrawlerProgress(max_workers=self.max_workers)
        self.results = self.progress_manager.run_tasks(
            items=self.temp_links,
            task_func=self._process_single_program,
            task_name="æŠ“å–è¿›åº¦",
            phase_name="Phase 2"
        )
    
    def _process_single_program(self, item: Dict) -> tuple:
        """
        å¤„ç†å•ä¸ªé¡¹ç›®çš„è¯¦æƒ…é¡µæŠ“å–
        
        å‚æ•°:
            item (Dict): åŒ…å« name, link å’Œ study_area çš„é¡¹ç›®ä¿¡æ¯
        
        è¿”å›:
            tuple: (ç»“æœå­—å…¸, è€—æ—¶ç§’æ•°)
        """
        item_start = time.time()
        
        # åˆ›å»ºç»“æœæ¨¡æ¿
        result = self.create_result_template(item['name'], item['link'])
        
        # è®¾ç½®å­¦ä¹ é¢†åŸŸ(ç›´æ¥ä½¿ç”¨Study area)
        result["å­¦é™¢/å­¦ä¹ é¢†åŸŸ"] = item.get('study_area', 'N/A')
        
        # è®¾ç½®ç»Ÿä¸€çš„ç”³è¯·é“¾æ¥
        result["ç”³è¯·é“¾æ¥"] = self.university_info.get("apply_register_url", "N/A")
        
        # ä»æµè§ˆå™¨æ± è·å–å®ä¾‹
        with self.browser_pool.get_browser() as driver:
            try:
                # è®¿é—®é¡¹ç›®è¯¦æƒ…é¡µ
                driver.get(item['link'])
                
                # ç­‰å¾…é¡µé¢åŠ è½½
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "h1, main"))
                )
                
                # æå–Key dates(deadline)
                result["é¡¹ç›®deadline"] = self._extract_key_dates(driver)
                
                # Deakinçš„opendateé€šå¸¸åœ¨Key datesä¸­ä¸€èµ·æ˜¾ç¤º
                # è¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥ç»†åŒ–æå–
                
            except TimeoutException:
                # è¯¦æƒ…é¡µåŠ è½½è¶…æ—¶
                pass
            except Exception:
                # å…¶ä»–é”™è¯¯
                pass
        
        duration = time.time() - item_start
        return result, duration
    
    def _extract_key_dates(self, driver) -> str:
        """
        æå–Key datesä¿¡æ¯
        
        ä»è¯¦æƒ…é¡µä¸­æŸ¥æ‰¾"Key dates"éƒ¨åˆ†,æå–deadlineä¿¡æ¯
        """
        try:
            # ç­–ç•¥1: æŸ¥æ‰¾ç‰¹å®šæ ‡é¢˜æ ‡ç­¾ (h3, h4, strong) åŒ…å« "Key dates"
            # è¿™æ ·å¯ä»¥é¿å…åŒ¹é…åˆ°å¯¼èˆªæ æˆ–å…¶ä»–æ— å…³åŒºåŸŸçš„ "Key dates" æ–‡æœ¬
            headers = driver.find_elements(
                By.XPATH,
                "//h3[contains(text(), 'Key dates')] | //h4[contains(text(), 'Key dates')] | //strong[contains(text(), 'Key dates')]"
            )
            
            for header in headers:
                try:
                    # å°è¯•1: è·å–ç´§é‚»çš„ä¸‹ä¸€ä¸ªå…„å¼Ÿå…ƒç´ 
                    # é€šå¸¸ Key dates æ ‡é¢˜ä¸‹ç´§è·Ÿä¸€ä¸ª p æ ‡ç­¾å«æœ‰å…·ä½“æ—¥æœŸ
                    try:
                        sibling = header.find_element(By.XPATH, "following-sibling::*[1]")
                        text = sibling.text.strip()
                        if text and len(text) > 10:
                            return text
                    except:
                        pass
                    
                    # å°è¯•2: å¦‚æœæ²¡æœ‰å…„å¼Ÿå…ƒç´ æˆ–å…„å¼Ÿå…ƒç´ ä¸ºç©ºï¼Œå°è¯•è·å–çˆ¶å®¹å™¨çš„æ–‡æœ¬
                    parent = header.find_element(By.XPATH, "./..")
                    text = parent.text.strip()
                    
                    if text and len(text) > 10:
                        # æ¸…ç†æ–‡æœ¬
                        cleaned_text = re.sub(r'\s+', ' ', text).strip()
                        # ç§»é™¤"Key dates"æ ‡é¢˜æœ¬èº«
                        cleaned_text = cleaned_text.replace('Key dates', '').strip()
                        
                        # ç®€å•çš„é•¿åº¦æ£€æŸ¥ï¼Œé¿å…è·å–åˆ°æ•´ä¸ªé¡µé¢çš„æ–‡æœ¬
                        if cleaned_text and len(cleaned_text) < 500:
                            return cleaned_text
                            
                except Exception:
                    continue
            
            # ç­–ç•¥2: ä¿ç•™åŸæœ‰çš„å®½æ³›æœç´¢ä½œä¸ºåå¤‡ï¼Œä½†å¢åŠ è¿‡æ»¤
            key_dates_section = driver.find_elements(
                By.XPATH,
                "//*[contains(text(), 'Key dates')]"
            )
            
            for section in key_dates_section:
                try:
                    # è·³è¿‡éšè—å…ƒç´ 
                    if not section.is_displayed():
                        continue

                    # è·å–çˆ¶å®¹å™¨æ–‡æœ¬
                    parent = section.find_element(By.XPATH, "./..")
                    text = parent.text.strip()
                    
                    # å¢åŠ è¿‡æ»¤ï¼šå¿…é¡»åŒ…å« "close" æˆ– "deadline" æˆ– "application"
                    if text and len(text) > 10:
                        cleaned_text = re.sub(r'\s+', ' ', text).strip()
                        cleaned_text = cleaned_text.replace('Key dates', '').strip()
                        
                        lower_text = cleaned_text.lower()
                        if ('close' in lower_text or 'deadline' in lower_text or 'application' in lower_text) and len(cleaned_text) < 300:
                             return cleaned_text

                except Exception:
                    continue

            return "N/A"
            
        except Exception:
            return "N/A"


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    with DeakinSpider(headless=False) as spider:
        results = spider.run()
        
        print(f"\næŠ“å–å®Œæˆ,å…± {len(results)} ä¸ªé¡¹ç›®")
        if results:
            import json
            print("\nå‰3ä¸ªé¡¹ç›®ç¤ºä¾‹:")
            print(json.dumps(results[:3], indent=2, ensure_ascii=False))
