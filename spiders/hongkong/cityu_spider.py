# -*- coding: utf-8 -*-
"""
é¦™æ¸¯åŸå¸‚å¤§å­¦ (CityU) çˆ¬è™«
ç›®æ ‡ç½‘å€: https://www.cityu.edu.hk/pg/taught-postgraduate-programmes/list
"""

import time
from typing import List, Dict, Tuple
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from spiders.base_spider import BaseSpider
from utils.progress import CrawlerProgress

class CityUSpider(BaseSpider):
    def __init__(self, headless: bool = True):
        # CityU æœ‰æå…¶ä¸¥æ ¼çš„ Incapsula WAF é˜²æŠ¤ï¼Œæ— å¤´æ¨¡å¼(Headless)å‡ ä¹å¿…æ­»
        # å› æ­¤è¿™é‡Œå¼ºåˆ¶è¦†ç›–ä¼ å…¥çš„ headless å‚æ•°ï¼Œå¿…é¡»ä½¿ç”¨æœ‰å¤´æ¨¡å¼
        print("ğŸ›¡ï¸ æ£€æµ‹åˆ° CityU å®‰å…¨é˜²æŠ¤ï¼Œå¼ºåˆ¶åˆ‡æ¢ä¸ºæœ‰å¤´æ¨¡å¼(Headful)ä»¥ç»•è¿‡æ‹¦æˆª...")
        super().__init__("cityu", headless=False)
        # å›ºå®šç”³è¯·é“¾æ¥
        self.apply_url = "https://banweb.cityu.edu.hk/pls/PROD/hwskalog_cityu.P_DispLoginNon"

    def run(self) -> List[Dict]:
        """
        æ‰§è¡Œçˆ¬è™«ä¸»æµç¨‹
        """
        print(f"ğŸš€ å¼€å§‹æŠ“å– {self.university_info['name']}...")
        print(f"ğŸ“ åˆ—è¡¨é¡µ: {self.university_info['list_url']}")
        
        self.results = []
        
        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šæ”¶é›†é¡¹ç›®é“¾æ¥
            print("ğŸ” æ­£åœ¨æ”¶é›†é¡¹ç›®åˆ—è¡¨...")
            items = self._collect_program_links()
            
            if not items:
                print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•é¡¹ç›®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–é€‰æ‹©å™¨")
                return []
            
            print(f"ğŸ“¦ å…±å‘ç° {len(items)} ä¸ªé¡¹ç›®ï¼Œå‡†å¤‡æŠ“å–è¯¦æƒ…...")
            
            # ç¬¬äºŒé˜¶æ®µï¼šå¹¶å‘æŠ“å–è¯¦æƒ…
            progress = CrawlerProgress(
                max_workers=10  # æ ¹æ®ç”¨æˆ·å¼ºåŠ²é…ç½® (12600KF/32G) è°ƒé«˜å¹¶å‘
            )
            
            self.results = progress.run_tasks(
                items=items,
                task_func=self._fetch_details,
                task_name="æŠ“å–è¯¦æƒ…",
                phase_name="CityU Details"
            )
            
        finally:
            # BaseSpider ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¼šè‡ªåŠ¨å…³é—­ä¸» driverï¼Œæ— éœ€æ‰‹åŠ¨å…³é—­
            pass
            
        # æ•°æ®å»é‡
        from utils.deduplicator import deduplicate_results
        self.results = deduplicate_results(self.results)
        
        self.print_summary()
        return self.results

    def _collect_program_links(self) -> List[Dict]:
        """
        ä»åˆ—è¡¨é¡µæ”¶é›†æ‰€æœ‰é¡¹ç›®é“¾æ¥
        ç­–ç•¥: å¿«é€Ÿæ‹ç…§æ³• - ä¸€æ¬¡æ€§æŠ“å– HTMLï¼Œé¿å…é¢‘ç¹ Selenium è°ƒç”¨è§¦å‘ WAF
        """
        self.driver.get(self.university_info['list_url'])
        
        # å¢åŠ é€šç”¨ç­‰å¾…
        try:
            WebDriverWait(self.driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        except:
            print("âš ï¸ é¡µé¢åŠ è½½åŸºç¡€å†…å®¹è¶…æ—¶")
        
        # ç­‰å¾…è¡¨æ ¼åŠ è½½
        try:
            WebDriverWait(self.driver, 20).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "div.table-responsive"))
            )
            # ç¨ä½œç­‰å¾…ç¡®ä¿æ¸²æŸ“å®Œæˆ
            time.sleep(5)
        except Exception as e:
            print(f"âš ï¸ ç­‰å¾…é¡µé¢è¡¨æ ¼åŠ è½½è¶…æ—¶: {e}")
            return []

        # ğŸ¯ å…³é”®ä¼˜åŒ–ï¼šä¸€æ¬¡æ€§æŠ“å–æ•´ä¸ªé¡µé¢æºä»£ç 
        print("ğŸ“¸ æ­£åœ¨æŠ“å–é¡µé¢å¿«ç…§ï¼ˆé¿å…è§¦å‘é˜²ç«å¢™ï¼‰...")
        page_html = self.driver.page_source
        
        # ä½¿ç”¨ BeautifulSoup ç¦»çº¿è§£æ
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(page_html, 'html.parser')
        
        items = []
        
        # æŸ¥æ‰¾æ‰€æœ‰å­¦é™¢çš„è¡¨æ ¼å®¹å™¨
        college_containers = soup.select("div.table-responsive")
        print(f"DEBUG: æ‰¾åˆ° {len(college_containers)} ä¸ªè¡¨æ ¼å®¹å™¨")
        
        for i, container in enumerate(college_containers):
            try:
                # è·å–å­¦é™¢åç§°
                college_code = container.get("data-college") or f"æœªçŸ¥å­¦é™¢_{i}"
                
                # æŸ¥æ‰¾è¡¨æ ¼è¡Œ
                rows = container.select("tr")
                
                for row in rows:
                    try:
                        # æŸ¥æ‰¾é¡¹ç›®é“¾æ¥å’Œåç§°
                        link_els = row.select("td.col-prog-title a")
                        
                        if not link_els:
                            continue
                            
                        link_el = link_els[0]
                        name = self._clean_text(link_el.get_text(strip=True))
                        url = link_el.get("href")
                        
                        if not name or not url:
                            continue
                        
                        # å¤„ç†ç›¸å¯¹é“¾æ¥
                        if url.startswith("/"):
                            url = self.university_info['base_url'] + url
                            
                        items.append({
                            "name": name,
                            "link": url,
                            "college": college_code
                        })
                    except Exception as e:
                        # ä¸å†æ‰“å°æ¯ä¸€è¡Œçš„é”™è¯¯ï¼ˆå¤ªåµï¼‰
                        continue
                        
            except Exception as e:
                print(f"âš ï¸ å¤„ç†å­¦é™¢è¡¨æ ¼æ—¶å‡ºé”™: {e}")
                continue
                
        print(f"âœ… æ€»å…±æ”¶é›†åˆ° {len(items)} ä¸ªé¡¹ç›®")
        return items

    def _fetch_details(self, item: Dict) -> Tuple[Dict, float]:
        """
        æŠ“å–å•ä¸ªé¡¹ç›®è¯¦æƒ…
        """
        # æ³¨æ„ï¼šè¿™é‡Œä¼šç”±å¤šçº¿ç¨‹è°ƒç”¨ï¼Œæ¯ä¸ªçº¿ç¨‹éœ€è¦åˆ›å»ºè‡ªå·±çš„ driver 
        # ä½† BaseSpider ç›®å‰è®¾è®¡æ˜¯å• driver æ¨¡å¼
        # è¿™é‡Œçš„ fetch_details è®¾è®¡éœ€è¦éµå¾ª CrawlerProgress çš„æ¨¡å¼
        # æˆ‘ä»¬ä½¿ç”¨ä¸´æ—¶ driver
        
        from utils.browser import get_driver, close_driver
        
        start_time = time.time()
        result = self.create_result_template(item["name"], item["link"])
        result["é¡¹ç›®ç”³è¯·é“¾æ¥"] = self.apply_url
        
        # å¯åŠ¨ä¸´æ—¶æµè§ˆå™¨
        # CityU è¯¦æƒ…é¡µä¹Ÿéœ€è¦ Headful æ¨¡å¼
        driver = get_driver(headless=False)
        
        try:
            driver.get(item['link'])
            
            # ç­‰å¾…å†…å®¹åŠ è½½
            try:
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "h1"))
                )
            except:
                pass
            
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…é¡µé¢ç»“æ„è§£æ
            # CityU è¯¦æƒ…é¡µé€šå¸¸åŒ…å«ï¼š
            # - Application Deadline (é€šå¸¸åœ¨è¡¨æ ¼ä¸­æˆ–æ–‡æœ¬ä¸­)
            # - Combined mode / Full-time mode details
            
            # è·å–é¡µé¢æ‰€æœ‰æ–‡æœ¬ç”¨äºç®€å•åŒ¹é…
            page_text = driver.find_element(By.TAG_NAME, "body").text
            
            # å°è¯•æŸ¥æ‰¾ Deadline
            # å¸¸è§æ ¼å¼: "Application Deadline: 31 May 2024" æˆ–è¡¨æ ¼ä¸­çš„ "Application Deadline"
            deadline = self._extract_deadline(driver, page_text)
            if deadline:
                result["é¡¹ç›®deadline"] = deadline
            
        except Exception as e:
            result["_error"] = str(e)
        finally:
            close_driver(driver)
            
        duration = time.time() - start_time
        return result, duration

    def _extract_deadline(self, driver, page_text: str) -> str:
        """
        å°è¯•æå– Application Deadline
        """
        # ç­–ç•¥ 0: æœ€ç²¾å‡†åŒ¹é… - ä½¿ç”¨ prog_admission ç±» (ç”¨æˆ·æä¾›çš„ç‰¹å®šç»“æ„)
        try:
            # ç›´æ¥å®šä½åŒ…å« prog_admission ç±»çš„ div
            # <div class="prog_info_block prog_admission">
            admission_block = driver.find_element(By.CSS_SELECTOR, "div.prog_info_block.prog_admission")
            content_span = admission_block.find_element(By.CSS_SELECTOR, "span.prog_content")
            
            raw_text = content_span.get_attribute("textContent").strip()
            # å¸¸è§å†…å®¹: "Local & Non-local : 28 Feb 2026"
            if "Deadline" in raw_text or "Non-local" in raw_text or ":" in raw_text:
                 if ":" in raw_text:
                     return raw_text.split(":", 1)[1].strip()
                 return raw_text
        except:
             pass

        # ç­–ç•¥ 1: éå† prog_info_block æŸ¥æ‰¾ Application Deadline æ ‡é¢˜
        try:
            h2_labels = driver.find_elements(By.CSS_SELECTOR, "div.prog_info_block h2.prog_label")
            for h2 in h2_labels:
                if "Application Deadline" in h2.text:
                    parent = h2.find_element(By.XPATH, "./parent::*")
                    content_span = parent.find_element(By.CSS_SELECTOR, "span.prog_content")
                    if content_span:
                        raw_text = content_span.get_attribute("textContent").strip()
                        if ":" in raw_text:
                            return raw_text.split(":", 1)[1].strip()
                        return raw_text
        except:
            pass

        # ç­–ç•¥ 2: æŸ¥æ‰¾è¡¨æ ¼è¡Œ (å¤‡ç”¨)
        try:
            deadline_labels = driver.find_elements(By.XPATH, "//*[contains(text(), 'Application Deadline')]")
            for label in deadline_labels:
                try:
                    parent_tr = label.find_element(By.XPATH, "./ancestor::tr")
                    row_text = parent_tr.text
                    clean_text = row_text.replace("Application Deadline", "").replace("Closing Date", "").strip()
                    if len(clean_text) > 5:
                        return clean_text
                except:
                    continue
        except:
            pass

        # ç­–ç•¥ 3: åŸºäºæ–‡æœ¬è¡Œçš„ä¸Šä¸‹æ–‡æŸ¥æ‰¾
        lines = [line.strip() for line in page_text.split('\n') if line.strip()]
        
        for i, line in enumerate(lines):
            # æ£€æŸ¥å½“å‰è¡Œæ˜¯å¦åŒ…å«å…³é”®è¯
            if "Application Deadline" in line or "Closing Date" in line:
                # æƒ…å†µ A: Deadline åœ¨åŒä¸€è¡Œ
                if ":" in line:
                    parts = line.split(":", 1)
                    val = parts[1].strip()
                    if len(val) > 5 and len(val) < 100:
                        return val
                
                # æƒ…å†µ B: Deadline åœ¨ä¸‹ä¸€è¡Œ
                if i + 1 < len(lines):
                    next_line = lines[i+1]
                    if "Non-local" in next_line or "Local" in next_line or any(m in next_line for m in ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]):
                         return next_line
            
            # æƒ…å†µ C: ç›´æ¥æŸ¥æ‰¾ "Non-local Applicants" æ‰€åœ¨çš„è¡Œ
            if "Non-local Applicants" in line and ":" in line:
                 parts = line.split(":", 1)
                 val = parts[1].strip()
                 return val

        return "N/A"
