# -*- coding: utf-8 -*-
"""
é¦™æ¸¯ç†å·¥å¤§å­¦ (PolyU) çˆ¬è™«
ç›®æ ‡ç½‘å€: https://www.polyu.edu.hk/study/pg/taught-postgraduate/find-your-programmes-tpg
"""

import time
from typing import List, Dict
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
from spiders.base_spider import BaseSpider

class PolyUSpider(BaseSpider):
    def __init__(self, headless: bool = True):
        super().__init__("polyu", headless=headless)
        # self.list_url is automatically derived from config
        self.apply_url = "https://www38.polyu.edu.hk/eAdmission/index.do"

    def run(self) -> List[Dict]:
        print(f"ğŸš€ å¼€å§‹æŠ“å– {self.university_info.get('name', 'PolyU')}...")
        print(f"ğŸ“ åˆ—è¡¨é¡µ: {self.list_url}")
        
        self.driver.get(self.list_url)
        
        # ç­‰å¾…åˆ—è¡¨åŠ è½½
        try:
            WebDriverWait(self.driver, 20).until(
                EC.presence_of_element_located((By.CLASS_NAME, "programmes-items"))
            )
            # ç¨ä½œç­‰å¾…ç¡®ä¿å†…å®¹æ¸²æŸ“
            time.sleep(5)
        except Exception as e:
            print(f"âš ï¸ ç­‰å¾…é¡¹ç›®åˆ—è¡¨åŠ è½½è¶…æ—¶: {e}")
            return []
            
        # è·å–é¡µé¢æºç è¿›è¡Œç¦»çº¿è§£æ
        print("ğŸ“¸ æŠ“å–é¡µé¢å¿«ç…§...")
        html = self.driver.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        results = []
        
        # æŸ¥æ‰¾æ‰€æœ‰é¡¹ç›®è¡Œ
        # æ ¹æ®æä¾›çš„HTMLï¼Œé¡¹ç›®åœ¨ .views-row ç±»ä¸­
        # æˆ‘ä»¬å¯ä»¥å®šä½ .programmes-items ä¸‹çš„ç›´æ¥å­å…ƒç´ æˆ– .views-row
        container = soup.select_one(".programmes-items")
        if not container:
            print("âš ï¸ æœªæ‰¾åˆ° .programmes-items å®¹å™¨")
            return []
            
        items = container.select(".views-row")
        print(f"ğŸ“¦ å‘ç° {len(items)} ä¸ªæ½œåœ¨é¡¹ç›®æ¡ç›®")
        
        for item in items:
            try:
                # æå–é“¾æ¥å…ƒç´ 
                link_el = item.select_one("a.programme")
                if not link_el:
                    continue
                    
                href = link_el.get("href")
                if not href:
                    continue
                    
                # å¤„ç†ç›¸å¯¹é“¾æ¥
                full_link = href
                if href.startswith("/"):
                    full_link = "https://www.polyu.edu.hk" + href
                elif not href.startswith("http"):
                    # è¿˜æœ‰å¯èƒ½æ˜¯ç›¸å¯¹è·¯å¾„ä½†æ²¡æœ‰æ–œæ ï¼Œè§†æƒ…å†µè€Œå®šï¼ŒPolyUé€šå¸¸æ˜¯ä»¥/å¼€å¤´
                    full_link = "https://www.polyu.edu.hk/" + href
                
                # æå–æ ‡é¢˜
                title_el = item.select_one(".title")
                title = title_el.get_text(strip=True) if title_el else ""
                
                # æå–å‰¯æ ‡é¢˜ (ä¸­æ–‡å)
                subtitle_el = item.select_one(".subtitle")
                subtitle = subtitle_el.get_text(strip=True) if subtitle_el else ""
                
                # ç»„åˆåç§°ï¼Œæ–¹ä¾¿è¯†åˆ«
                full_name = f"{title} {subtitle}".strip()
                
                # æå–æˆªæ­¢æ—¥æœŸ
                deadline = "N/A"
                deadline_el = item.select_one(".deadline-section")
                if deadline_el:
                    # ä¼˜å…ˆæŸ¥æ‰¾ Non-Local
                    non_local_div = deadline_el.find("div", string=lambda t: t and "Non-Local" in t)
                    if non_local_div:
                        raw_dl = non_local_div.get_text(strip=True)
                        # æ ¼å¼: "Non-Local Application Deadline: 15 Jan 2026 (Main Round)"
                        # æå–å†’å·åçš„éƒ¨åˆ†
                        if ":" in raw_dl:
                            deadline = raw_dl.split(":", 1)[1].strip()
                        else:
                            deadline = raw_dl
                    else:
                        # å¦‚æœæ²¡æœ‰ Non-Localï¼Œå°è¯• Local
                        local_div = deadline_el.find("div", string=lambda t: t and "Local" in t)
                        if local_div:
                             raw_dl = local_div.get_text(strip=True)
                             if ":" in raw_dl:
                                deadline = raw_dl.split(":", 1)[1].strip()
                             else:
                                deadline = raw_dl
                
                program_data = {
                    "program_name": title,  # ä¿æŒåŸå§‹è‹±æ–‡åä½œä¸ºä¸»é”®
                    "program_name_cn": subtitle,
                    "link": full_link,
                    "deadline": deadline,
                    "application_link": self.apply_url,
                    "university": "PolyU",
                    "country": "Hong Kong"
                }
                
                results.append(program_data)
                
            except Exception as e:
                print(f"âš ï¸ è§£ææ¡ç›®å‡ºé”™: {e}")
                continue
                
        # è¿‡æ»¤åšå£«é¡¹ç›®
        filtered_results = self.filter_doctor_programmes(results)
        
        print(f"âœ… æŠ“å–å®Œæˆï¼ŒåŸå§‹æ•°é‡: {len(results)}ï¼Œè¿‡æ»¤åæ•°é‡: {len(filtered_results)}")
        return filtered_results

    def filter_doctor_programmes(self, items: List[Dict]) -> List[Dict]:
        """
        è¿‡æ»¤åšå£« (Doctor/PhD) é¡¹ç›®
        """
        filtered = []
        doctor_keywords = ["Doctor", "PhD", "D.B.A.", "EngD", "Philosophy"]
        
        for item in items:
            name = item.get("program_name", "")
            cn_name = item.get("program_name_cn", "")
            
            is_doctor = False
            for kw in doctor_keywords:
                if kw in name or kw in cn_name:
                    is_doctor = True
                    break
            
            # ä¹Ÿå¯ä»¥æ£€æŸ¥ä¸­æ–‡ "åšå£«"
            if "åšå£«" in cn_name:
                is_doctor = True
                
            if not is_doctor:
                filtered.append(item)
            else:
                # print(f"ğŸš« è¿‡æ»¤åšå£«é¡¹ç›®: {name}") # è°ƒè¯•ç”¨
                pass
                
        return filtered

if __name__ == "__main__":
    # ç®€å•çš„æµ‹è¯•è¿è¡Œé€»è¾‘
    spider = PolyUSpider(headless=False)
    results = spider.run()
    import json
    print(json.dumps(results, indent=2, ensure_ascii=False))
